{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization and list connections/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import promptflow\n",
    "\n",
    "pf = promptflow.PFClient()\n",
    "\n",
    "# List all the available connections\n",
    "for c in pf.connections.list():\n",
    "    print(c.name + \" (\" + c.type + \")\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create connections\n",
    "Connection in prompt flow is for managing settings of your application behaviors incl. how to talk to different services (Azure OpenAI for example).\n",
    "In many applications, configuration files or environment variables are used for this purpose. Chat_with_pdf also uses environment variables, to make it work with prompt flow and without changing how environment variables are used, we populate everything in the CustomConnection into environment variables.\n",
    "```python\n",
    "def setup_env(conn: CustomConnection):\n",
    "    if not conn:\n",
    "        return\n",
    "    for key in conn:\n",
    "        os.environ[key] = conn[key]\n",
    "```\n",
    "\n",
    "chat_with_pdf requires following env vars (thus for the custom connection named \"chat_with_pdf_custom_connection\"):\n",
    "```\n",
    "OPENAI_API_BASE=<AOAI_ENDPOINT>\n",
    "OPENAI_API_VERSION=2023-03-15-preview\n",
    "OPENAI_API_KEY=<AOAI_API_KEY>\n",
    "EMBEDDING_MODEL_DEPLOYMENT_NAME=text-embedding-ada-002\n",
    "CHAT_MODEL_DEPLOYMENT_NAME=gpt-35-turbo\n",
    "PROMPT_TOKEN_LIMIT=3000\n",
    "MAX_COMPLETION_TOKENS=256\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.entities import CustomConnection\n",
    "\n",
    "conn_name = 'chat_with_pdf_custom_connection'\n",
    "\n",
    "if len([c for c in pf.connections.list() if c.name == conn_name]) == 0:\n",
    "    # Create the custom connection that is required by chat_with_pdf_tool\n",
    "    print(f\"Creating custom connection: {conn_name}\")\n",
    "    conn = CustomConnection(\n",
    "        name = conn_name,\n",
    "        configs= {\n",
    "            \"OPENAI_API_VERSION\": \"2023-03-15-preview\",\n",
    "            \"EMBEDDING_MODEL_DEPLOYMENT_NAME\": \"text-embedding-ada-002\",\n",
    "            \"CHAT_MODEL_DEPLOYMENT_NAME\": \"gpt-35-turbo\",\n",
    "            \"PROMPT_TOKEN_LIMIT\": \"3000\",\n",
    "            \"MAX_COMPLETION_TOKENS\": \"256\"\n",
    "        },\n",
    "        secrets= {\n",
    "            \"OPENAI_API_BASE\": \"AOAI_ENDPOINT\", # replace this\n",
    "            \"OPENAI_API_KEY\": \"AOAI_API_KEY\", # replace this\n",
    "        })\n",
    "    pf.connections.create_or_update(conn)\n",
    "    print(f\"Custom connection: {conn_name} created.\")\n",
    "else:\n",
    "    print(f\"Custom connection: {conn_name} found.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pf.flows.test('.', inputs={'chat_history': [], 'pdf_url': 'https://arxiv.org/pdf/1810.04805.pdf', 'question': 'what is BERT?'})\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the flow with a data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_path = \".\"\n",
    "data_path = \"./data/bert-paper-qna.jsonl\"\n",
    "\n",
    "run = pf.run(flow=flow_path, data=data_path)\n",
    "pf.stream(run)\n",
    "\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.get_details(run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
