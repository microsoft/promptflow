{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat with PDF (WIP)\n",
    "\n",
    "This is a simple flow that allow you to ask questions about the content of a PDF file and get answers.\n",
    "You can run the flow with a URL to a PDF file and question as argument.\n",
    "Once it's launched it will download the PDF and build an index of the content. \n",
    "Then when you ask a question, it will look up the index to retrieve relevant content and post the question with the relevant content to OpenAI chat model (gpt-3.5-turbo or gpt4) to get an answer.\n",
    "\n",
    "## 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "# Get a handle to workspace\n",
    "ml_client = MLClient.from_config(credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Get familiar with the primary interface - PFClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import promptflow.azure as azure\n",
    "\n",
    "pf = azure.PFClient(ml_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Create necessary connections\n",
    "\n",
    "Connection in prompt flow is for managing settings of your application behaviors incl. how to talk to different services (Azure OpenAI for example).\n",
    "In many applications, configuration files or environment variables are used for this purpose. Chat_with_pdf also uses environment variables, to make it work with prompt flow and without changing how environment variables are used, we populate everything in the CustomConnection into environment variables.\n",
    "```python\n",
    "def setup_env(conn: CustomConnection):\n",
    "    if not conn:\n",
    "        return\n",
    "    for key in conn:\n",
    "        os.environ[key] = conn[key]\n",
    "```\n",
    "\n",
    "chat_with_pdf requires following env vars (thus for the custom connection named `chat_with_pdf_custom_connection`):\n",
    "```\n",
    "OPENAI_API_BASE=<AOAI_ENDPOINT>\n",
    "OPENAI_API_VERSION=2023-03-15-preview\n",
    "OPENAI_API_KEY=<AOAI_API_KEY>\n",
    "EMBEDDING_MODEL_DEPLOYMENT_NAME=text-embedding-ada-002\n",
    "CHAT_MODEL_DEPLOYMENT_NAME=gpt-35-turbo\n",
    "PROMPT_TOKEN_LIMIT=3000\n",
    "MAX_COMPLETION_TOKENS=256\n",
    "```\n",
    "\n",
    "\n",
    "Prepare your Azure Open AI resource follow this [instruction](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal) and get your `api_key` if you don't have one.\n",
    "\n",
    "Please go to [workspace portal](https://ml.azure.com/), click `Prompt flow` -> `Connections` -> `Create`, then follow the instruction to create your own connections. \n",
    "Learn more on [connections](https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/concept-connections?view=azureml-api-2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.entities import CustomConnection\n",
    "\n",
    "conn_name = \"chat_with_pdf_custom_connection\"\n",
    "\n",
    "conn = CustomConnection(\n",
    "    name=conn_name,\n",
    "    configs={\n",
    "        \"OPENAI_API_VERSION\": \"2023-03-15-preview\",\n",
    "        \"EMBEDDING_MODEL_DEPLOYMENT_NAME\": \"text-embedding-ada-002\",\n",
    "        \"CHAT_MODEL_DEPLOYMENT_NAME\": \"gpt-35-turbo\",\n",
    "        \"PROMPT_TOKEN_LIMIT\": \"3000\",\n",
    "        \"MAX_COMPLETION_TOKENS\": \"256\",\n",
    "    },\n",
    "    secrets={\n",
    "        \"OPENAI_API_BASE\": \"AOAI_ENDPOINT\",  # replace this\n",
    "        \"OPENAI_API_KEY\": \"AOAI_API_KEY\",  # replace this\n",
    "    },\n",
    ")\n",
    "\n",
    "# currently we only support create connection in Azure ML Studio UI\n",
    "# raise Exception(f\"Please create {conn_name} connection in Azure ML Studio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Run a flow with settings in custom connection (context size 3K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_path = \".\"\n",
    "data_path = \"./data/bert-paper-qna.jsonl\"\n",
    "\n",
    "run_3k_context = pf.run(\n",
    "    flow=flow_path,\n",
    "    data=data_path,\n",
    "    connections={\"setup_env\": {\"conn\": \"chat_with_pdf_custom_connection\"}},\n",
    "    display_name=\"chat_with_pdf_3k_context\",\n",
    "    tags={\"chat_with_pdf\": \"\", \"2nd_round\": \"\"},\n",
    "    stream=True,\n",
    ")\n",
    "pf.stream(run_3k_context)\n",
    "\n",
    "print(run_3k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail = pf.get_details(run_3k_context)\n",
    "\n",
    "detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run a flow with settings in custom connection (context size 2K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume user have created a connection with below setting\n",
    "# \"PROMPT_TOKEN_LIMIT\": \"3000\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_path = \".\"\n",
    "data_path = \"./test_data/bert-paper-qna.jsonl\"\n",
    "\n",
    "run_2k_context = pf.run(\n",
    "    flow=flow_path,\n",
    "    data=data_path,\n",
    "    connections={\n",
    "        \"setup_env\": {\"conn\": \"chat_with_pdf_custom_connection_smaller_context\"}\n",
    "    },\n",
    "    display_name=\"chat_with_pdf_2k_context\",\n",
    "    tags={\"chat_with_pdf\": \"\", \"2nd_round\": \"\"},\n",
    "    stream=True,\n",
    ")\n",
    "pf.stream(run_2k_context)\n",
    "\n",
    "print(run_2k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail = pf.get_details(run_2k_context)\n",
    "\n",
    "detail"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
