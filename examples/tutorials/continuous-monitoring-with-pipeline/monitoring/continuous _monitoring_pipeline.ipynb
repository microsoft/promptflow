{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Monitoring Pipeline\n",
    "This tutorial describes an advanced use case of [running flows in Azure ML Pipelines](../run-flow-with-pipeline/pipeline.ipynb).  \n",
    "Continuous monitoring is necessary to maintain the quality, performance and efficiency of Generative AI applications.  \n",
    "These factors directly impact the user experience and operational costs.  \n",
    "\n",
    "We will run evaluations on a basic chatbot flow, then aggregate the results to export and visualize the metrics.  \n",
    "The flows used in this pipeline are described below:\n",
    "- [Basic Chat](../../../flows/chat/chat-basic/)\n",
    "- [Q&A Evaluation](../../../flows/evaluation/eval-qna-rag-metrics/)\n",
    "- [Perceived Intelligence Evaluation](../../../flows/evaluation/eval-perceived-intelligence/)\n",
    "- [Simple Summarization](../flows/standard/simple-summarization/)\n",
    "- [Summarization Evaluation](../../../flows/evaluation/eval-summarization/)\n",
    "\n",
    "![continuous_monitoring_pipeline.png](./media/continuous_monitoring_pipeline.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Import the required libraries\n",
    "## Install the required python packages\n",
    "Make sure version of ‘azure-ai-ml’ is higher than 1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient, load_component, Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Configure credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Get a handle to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ./config.json\n"
     ]
    }
   ],
   "source": [
    "# Get a handle to workspace\n",
    "ml_client = MLClient.from_config(credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4.1 Validate Basic Chat Flow\n",
    "## Import the flow required packages\n",
    "pip install -r ../../../flows/chat/chat-basic/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\": \"Succeeded\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!pf flow validate --source ../../../flows/chat/chat-basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4.2 Validate QnA RAG Evaluation Flow\n",
    "## Import the flow required packages\n",
    "pip install -r ../../../flows/evaluation/eval-qna-rag-metrics/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\": \"Succeeded\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!pf flow validate --source ../../../flows/evaluation/eval-qna-rag-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4.3 Validate Perceived Intelligence Evaluation Flow\n",
    "## Import the flow required packages\n",
    "pip install -r ../../../flows/evaluation/eval-perceived-intelligence/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\": \"Succeeded\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!pf flow validate --source ../../../flows/evaluation/eval-perceived-intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4.4 Validate Summarization flow\n",
    "pip install -r ../flows/standard/simple-summarization/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\": \"Succeeded\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!pf flow validate --source ../flows/standard/simple-summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4.5 Validate Summarization Evaluation flow\n",
    "pip install -r ../../../flows/evaluation/eval-summarization/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-29 14:20:53,803 - root - WARNING - 'from promptflow import tool' is deprecated and will be removed in the future. Use 'from promptflow.core import tool' instead.\n",
      "{\n",
      "  \"result\": \"Succeeded\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!pf flow validate --source ../../../flows/evaluation/eval-summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Chat flow as component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_flow_component = load_component(\"../../../flows/chat/chat-basic/flow.dag.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Load QnA RAG Evaluation flow as component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_qna_rag_metrics_component = load_component(\"../../../flows/evaluation/eval-qna-rag-metrics/flow.dag.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Load Perceived Intelligence flow as component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_perceived_intelligence_component = load_component(\"../../../flows/evaluation/eval-perceived-intelligence/flow.dag.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Load Summarization flow as component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_summarization_component = load_component(\"../flows/standard/simple-summarization/flow.dag.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Load Summarization Evaluation flow as component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_summarization_component = load_component(\"../../../flows/evaluation/eval-summarization/flow.dag.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Load Parquet Converter\n",
    "The Parquet Converter is a Command Component that aggregates the results of the evaluations node and logs the metrics to ML Pipelines.  \n",
    "\n",
    "![convert_parquet.png](./media/convert_parquet.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "convert_parquet_component = load_component(\"./components/convert_parquet/convert_parquet.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Declare input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = Input(\n",
    "    path=\"./data/monitoring_dataset.csv\",\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    mode=\"mount\",\n",
    ")\n",
    "\n",
    "eval_results_output = Output(\n",
    "    # Provide custom flow output file path if needed\n",
    "    path=\"azureml://subscriptions/ac0c693d-f31e-4fb1-9fdf-0cbddd556fb7/resourcegroups/rg-khia3sharinghub/workspaces/khi-a3-sharing/datastores/workspaceblobstore/paths/data_ingestion_eval/\",\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    # rw_mount is suggested for flow output\n",
    "    mode=\"rw_mount\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2.1 Run pipeline with single flow component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated: data (1786114619.py, line 191)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 191\u001b[0;36m\u001b[0m\n\u001b[0;31m    eval_summarization_node = eval_summarization_component(\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated: data\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline as a function\n",
    "@pipeline()\n",
    "def continuous_monitoring(\n",
    "    # Function inputs will be treated as pipeline input data or parameters.\n",
    "    # Pipeline input could be linked to step inputs to pass data between steps.\n",
    "    # Users are not required to define pipeline inputs.\n",
    "    # With pipeline inputs, user can provide the different data or values when they trigger different pipeline runs.\n",
    "    pipeline_input_data: Input,\n",
    "    parallel_node_count: int = 1,\n",
    "):\n",
    "    # Declare pipeline step 'flow_node' by using flow component\n",
    "    chat_flow_node = chat_flow_component(\n",
    "        # Bind the pipeline input data to the port 'data' of the flow component\n",
    "        # If you don't have pipeline input, you can directly pass the 'data_input' object to the 'data'\n",
    "        # But with this approach, you can't provide different data when you trigger different pipeline runs.\n",
    "        data=pipeline_input_data,\n",
    "        # Declare which column of input data should be mapped to flow input\n",
    "        # the value pattern follows ${data.<column_name_from_data_input>}\n",
    "        chat_history='${data.chat_history}',\n",
    "        question='${data.question}',\n",
    "        # Provide the connection values of the flow component\n",
    "        # The value of connection and deployment_name should align with your workspace connection settings.\n",
    "        connections={\n",
    "            \"chat\": {\n",
    "                \"connection\": \"ai-khia3sharinghub628941560419_aoai\",\n",
    "                \"deployment_name\": \"gpt-35-turbo\"\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Provide run settings of your flow component\n",
    "    # Only 'compute' is required and other setting will keep default value if not provided.\n",
    "    # If the workspace has been created with Azure AI Studio is inside a hub,\n",
    "    # a Compute Cluster cannot be used, use a Serverless instance instead.\n",
    "    chat_flow_node.environment_variables = {\n",
    "        \"PF_INPUT_FORMAT\": \"csv\",\n",
    "    }\n",
    "    chat_flow_node.compute = \"serverless\"\n",
    "    chat_flow_node.resources = {\"instance_count\": parallel_node_count}\n",
    "    chat_flow_node.mini_batch_size = 5\n",
    "    chat_flow_node.max_concurrency_per_instance = 2\n",
    "    chat_flow_node.retry_settings = {\n",
    "        \"max_retries\": 1,\n",
    "        \"timeout\": 1200,\n",
    "    }\n",
    "    chat_flow_node.error_threshold = -1\n",
    "    chat_flow_node.mini_batch_error_threshold = -1\n",
    "    chat_flow_node.logging_level = \"DEBUG\"\n",
    "\n",
    "    # QnA RAG Metrics Evaluation Node\n",
    "    eval_qna_rag_metrics_node = eval_qna_rag_metrics_component(\n",
    "        # Bind the pipeline input data to the port 'data' of the flow component\n",
    "        # If you don't have pipeline input, you can directly pass the 'data_input' object to the 'data'\n",
    "        # But with this approach, you can't provide different data when you trigger different pipeline runs.\n",
    "        data=pipeline_input_data,\n",
    "        # run_outputs connects the output of a previous node\n",
    "        run_outputs=chat_flow_node.outputs.flow_outputs,\n",
    "        # Declare which column of input data should be mapped to flow input\n",
    "        # the value pattern follows ${data.<column_name_from_data_input>}\n",
    "        documents='${data.documents}',\n",
    "        question='${data.question}',\n",
    "        # Declare which column of previous node output should be mapped to flow input\n",
    "        # the value pattern follows ${run.outputs.<column_name_from_data_input>}\n",
    "        answer='${run.outputs.answer}',\n",
    "        # Provide the connection values of the flow component\n",
    "        # The value of connection and deployment_name should align with your workspace connection settings.\n",
    "        connections={\n",
    "            \"gpt_groundedness\": {\n",
    "                \"connection\": \"ai-khia3sharinghub628941560419_aoai\",\n",
    "                \"deployment_name\": \"gpt-35-turbo\"\n",
    "            },\n",
    "            \"gpt_relevance\": {\n",
    "                \"connection\": \"ai-khia3sharinghub628941560419_aoai\",\n",
    "                \"deployment_name\": \"gpt-35-turbo\"\n",
    "            },\n",
    "            \"gpt_retrieval_score\": {\n",
    "                \"connection\": \"ai-khia3sharinghub628941560419_aoai\",\n",
    "                \"deployment_name\": \"gpt-35-turbo\"\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Provide run settings of your flow component\n",
    "    # Only 'compute' is required and other setting will keep default value if not provided.\n",
    "    # If the workspace has been created with Azure AI Studio is inside a hub,\n",
    "    # a Compute Cluster cannot be used, use a Serverless instance instead.\n",
    "    eval_qna_rag_metrics_node.environment_variables = {\n",
    "        \"PF_INPUT_FORMAT\": \"csv\",\n",
    "    }\n",
    "    eval_qna_rag_metrics_node.compute = \"serverless\"\n",
    "    eval_qna_rag_metrics_node.resources = {\"instance_count\": parallel_node_count}\n",
    "    eval_qna_rag_metrics_node.mini_batch_size = 5\n",
    "    eval_qna_rag_metrics_node.max_concurrency_per_instance = 2\n",
    "    eval_qna_rag_metrics_node.retry_settings = {\n",
    "        \"max_retries\": 1,\n",
    "        \"timeout\": 1200,\n",
    "    }\n",
    "    eval_qna_rag_metrics_node.error_threshold = -1\n",
    "    eval_qna_rag_metrics_node.mini_batch_error_threshold = -1\n",
    "    eval_qna_rag_metrics_node.logging_level = \"DEBUG\"\n",
    "\n",
    "    # Perceived Intelligence Evaluation Node\n",
    "    eval_perceived_intelligence_node = eval_perceived_intelligence_component(\n",
    "        # Bind the pipeline input data to the port 'data' of the flow component\n",
    "        # If you don't have pipeline input, you can directly pass the 'data_input' object to the 'data'\n",
    "        # But with this approach, you can't provide different data when you trigger different pipeline runs.\n",
    "        data=pipeline_input_data,\n",
    "        # run_outputs connects the output of a previous node\n",
    "        run_outputs=chat_flow_node.outputs.flow_outputs,\n",
    "        # Declare which column of input data should be mapped to flow input\n",
    "        # the value pattern follows ${data.<column_name_from_data_input>}\n",
    "        question='${data.question}',\n",
    "        context='${data.context}',\n",
    "        # Declare which column of previous node output should be mapped to flow input\n",
    "        # the value pattern follows ${run.outputs.<column_name_from_data_input>}\n",
    "        answer='${run.outputs.answer}',\n",
    "        # Provide the connection values of the flow component\n",
    "        # The value of connection and deployment_name should align with your workspace connection settings.\n",
    "        connections={\n",
    "            \"gpt_perceived_intelligence\": {\n",
    "                \"connection\": \"ai-khia3sharinghub628941560419_aoai\",\n",
    "                \"deployment_name\": \"gpt-35-turbo\"\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Provide run settings of your flow component\n",
    "    # Only 'compute' is required and other setting will keep default value if not provided.\n",
    "    # If the workspace has been created with Azure AI Studio is inside a hub,\n",
    "    # a Compute Cluster cannot be used, use a Serverless instance instead.\n",
    "    eval_perceived_intelligence_node.environment_variables = {\n",
    "        \"PF_INPUT_FORMAT\": \"csv\",\n",
    "    }\n",
    "    eval_perceived_intelligence_node.compute = \"serverless\"\n",
    "    eval_perceived_intelligence_node.resources = {\"instance_count\": parallel_node_count}\n",
    "    eval_perceived_intelligence_node.mini_batch_size = 5\n",
    "    eval_perceived_intelligence_node.max_concurrency_per_instance = 2\n",
    "    eval_perceived_intelligence_node.retry_settings = {\n",
    "        \"max_retries\": 1,\n",
    "        \"timeout\": 1200,\n",
    "    }\n",
    "    eval_perceived_intelligence_node.error_threshold = -1\n",
    "    eval_perceived_intelligence_node.mini_batch_error_threshold = -1\n",
    "    eval_perceived_intelligence_node.logging_level = \"DEBUG\"\n",
    "\n",
    "    # Summarization Node\n",
    "    simple_summarization_node = simple_summarization_component(\n",
    "        # Bind the pipeline input data to the port 'data' of the flow component\n",
    "        # If you don't have pipeline input, you can directly pass the 'data_input' object to the 'data'\n",
    "        # But with this approach, you can't provide different data when you trigger different pipeline runs.\n",
    "        data=pipeline_input_data,\n",
    "        # run_outputs connects the output of a previous node\n",
    "        run_outputs=chat_flow_node.outputs.flow_outputs,\n",
    "        # Declare which column of previous node output should be mapped to flow input\n",
    "        # the value pattern follows ${run.outputs.<column_name_from_data_input>}\n",
    "        answer='${run.outputs.answer}',\n",
    "        # Provide the connection values of the flow component\n",
    "        # The value of connection and deployment_name should align with your workspace connection settings.\n",
    "        connections={\n",
    "            \"summarize_text_content\": {\n",
    "                \"connection\": \"ai-khia3sharinghub628941560419_aoai\",\n",
    "                \"deployment_name\": \"gpt-35-turbo\"\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Provide run settings of your flow component\n",
    "    # Only 'compute' is required and other setting will keep default value if not provided.\n",
    "    # If the workspace has been created with Azure AI Studio is inside a hub,\n",
    "    # a Compute Cluster cannot be used, use a Serverless instance instead.\n",
    "    simple_summarization_node.environment_variables = {\n",
    "        \"PF_INPUT_FORMAT\": \"csv\",\n",
    "    }\n",
    "    simple_summarization_node.compute = \"serverless\"\n",
    "    simple_summarization_node.resources = {\"instance_count\": parallel_node_count}\n",
    "    simple_summarization_node.mini_batch_size = 5\n",
    "    simple_summarization_node.max_concurrency_per_instance = 2\n",
    "    simple_summarization_node.retry_settings = {\n",
    "        \"max_retries\": 1,\n",
    "        \"timeout\": 1200,\n",
    "    }\n",
    "    simple_summarization_node.error_threshold = -1\n",
    "    simple_summarization_node.mini_batch_error_threshold = -1\n",
    "    simple_summarization_node.logging_level = \"DEBUG\"\n",
    "\n",
    "    # Summarization Evaluation Node\n",
    "    eval_summarization_node = eval_summarization_component(\n",
    "        # Bind the pipeline input data to the port 'data' of the flow component\n",
    "        # If you don't have pipeline input, you can directly pass the 'data_input' object to the 'data'\n",
    "        # But with this approach, you can't provide different data when you trigger different pipeline runs.\n",
    "        data=simple_summarization_node.outputs.flow_outputs,\n",
    "        # run_outputs connects the output of a previous node\n",
    "        run_outputs=chat_flow_node.outputs.flow_outputs,\n",
    "        # Declare which column of input data should be mapped to flow input\n",
    "        # the value pattern follows ${data.<column_name_from_data_input>}\n",
    "        summary='${data.summary}',\n",
    "        # Declare which column of previous node output should be mapped to flow input\n",
    "        # the value pattern follows ${run.outputs.<column_name_from_data_input>}\n",
    "        document='${run.outputs.answer}',\n",
    "        # Provide the connection values of the flow component\n",
    "        # The value of connection and deployment_name should align with your workspace connection settings.\n",
    "        connections={\n",
    "            \"score_fluency\": {\n",
    "                \"connection\": \"ai-khia3sharinghub628941560419_aoai\",\n",
    "            },\n",
    "            \"score_consistency\": {\n",
    "                \"connection\": \"ai-khia3sharinghub628941560419_aoai\",\n",
    "                # \"deployment_name\": \"gpt-35-turbo\"\n",
    "            },\n",
    "            \"score_relevance\": {\n",
    "                \"connection\": \"ai-khia3sharinghub628941560419_aoai\",\n",
    "                # \"deployment_name\": \"gpt-35-turbo\"\n",
    "            },\n",
    "            \"score_coherence\": {\n",
    "                \"connection\": \"ai-khia3sharinghub628941560419_aoai\",\n",
    "                # \"deployment_name\": \"gpt-35-turbo\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Provide run settings of your flow component\n",
    "    # Only 'compute' is required and other setting will keep default value if not provided.\n",
    "    # If the workspace has been created with Azure AI Studio is inside a hub,\n",
    "    # a Compute Cluster cannot be used, use a Serverless instance instead.\n",
    "    eval_summarization_node.environment_variables = {\n",
    "        \"PF_INPUT_FORMAT\": \"jsonl\",\n",
    "    }\n",
    "    eval_summarization_node.compute = \"serverless\"\n",
    "    eval_summarization_node.resources = {\"instance_count\": parallel_node_count}\n",
    "    eval_summarization_node.mini_batch_size = 5\n",
    "    eval_summarization_node.max_concurrency_per_instance = 2\n",
    "    eval_summarization_node.retry_settings = {\n",
    "        \"max_retries\": 1,\n",
    "        \"timeout\": 1200,\n",
    "    }\n",
    "    eval_summarization_node.error_threshold = -1\n",
    "    eval_summarization_node.mini_batch_error_threshold = -1\n",
    "    eval_summarization_node.logging_level = \"DEBUG\"\n",
    "\n",
    "    convert_parquet_node = convert_parquet_component(\n",
    "        # Bind the evaluation nodes outputs to the command component's input\n",
    "        eval_qna_rag_metrics_output_folder=eval_qna_rag_metrics_node.outputs.flow_outputs,\n",
    "        eval_perceived_intelligence_output_folder=eval_perceived_intelligence_node.outputs.flow_outputs,\n",
    "        eval_summarization_output_folder=eval_summarization_node.outputs.flow_outputs\n",
    "    )\n",
    "\n",
    "    # Provide run settings of your flow component\n",
    "    # Only 'compute' is required and other setting will keep default value if not provided.\n",
    "    # If the workspace has been created with Azure AI Studio is inside a hub,\n",
    "    # a Compute Cluster cannot be used, use a Serverless instance instead.\n",
    "    convert_parquet_node.compute = \"serverless\"\n",
    "    # Function return will be treated as pipeline output. This is not required.\n",
    "    return {\"eval_results_output_folder\": convert_parquet_node.outputs.eval_results_output}\n",
    "\n",
    "# create pipeline instance\n",
    "pipeline_job_def = continuous_monitoring(pipeline_input_data=data_input)\n",
    "pipeline_job_def.outputs.eval_results_output_folder = eval_results_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "ename": "MlException",
     "evalue": "{\n  \"result\": \"Failed\",\n  \"errors\": [\n    {\n      \"message\": \"Required input 'data' for component 'simple_summarization_node' not provided.\",\n      \"path\": \"jobs.simple_summarization_node.inputs.data\",\n      \"value\": null\n    }\n  ]\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:660\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_validation:\n\u001b[0;32m--> 660\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_on_failure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# Create all dependent resources\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:372\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, dimensions) \u001b[38;5;28;01mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 372\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;66;03m# collect from return if no dimensions from parameter\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:562\u001b[0m, in \u001b[0;36mJobOperations._validate\u001b[0;34m(self, job, raise_on_failure, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m git_code_validation_result\u001b[38;5;241m.\u001b[39mtry_raise(\n\u001b[1;32m    558\u001b[0m         raise_error\u001b[38;5;241m=\u001b[39mraise_on_failure,\n\u001b[1;32m    559\u001b[0m         error_func\u001b[38;5;241m=\u001b[39merror_func,\n\u001b[1;32m    560\u001b[0m     )\n\u001b[0;32m--> 562\u001b[0m validation_result \u001b[38;5;241m=\u001b[39m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_failure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m validation_result\u001b[38;5;241m.\u001b[39mmerge_with(git_code_validation_result)\n",
      "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.9/site-packages/azure/ai/ml/entities/_validation/schema.py:122\u001b[0m, in \u001b[0;36mSchemaValidatableMixin._validate\u001b[0;34m(self, raise_error)\u001b[0m\n\u001b[1;32m    121\u001b[0m result\u001b[38;5;241m.\u001b[39mmerge_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_customized_validate())\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.9/site-packages/azure/ai/ml/entities/_validation/schema.py:109\u001b[0m, in \u001b[0;36mSchemaValidatableMixin._try_raise\u001b[0;34m(cls, validation_result, raise_error)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_raise\u001b[39m(\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mcls\u001b[39m, validation_result: MutableValidationResult, \u001b[38;5;241m*\u001b[39m, raise_error: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    108\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m MutableValidationResult:\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalidation_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_validation_error\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.9/site-packages/azure/ai/ml/entities/_validation/core.py:253\u001b[0m, in \u001b[0;36mMutableValidationResult.try_raise\u001b[0;34m(self, raise_error, error_func)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m ValidationError(message\u001b[38;5;241m=\u001b[39mmsg)\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_func(\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m(),\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation failed on the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_messages),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValidationException\u001b[0m: {\n  \"result\": \"Failed\",\n  \"errors\": [\n    {\n      \"message\": \"Required input 'data' for component 'simple_summarization_node' not provided.\",\n      \"path\": \"jobs.simple_summarization_node.inputs.data\",\n      \"value\": null\n    }\n  ]\n}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Submit the pipeline job to your workspace\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pipeline_job_run \u001b[38;5;241m=\u001b[39m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline_job_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContinuous Monitoring\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m pipeline_job_run\n\u001b[1;32m      7\u001b[0m ml_client\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mstream(pipeline_job_run\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.9/site-packages/azure/core/tracing/decorator.py:94\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:372\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m dimensions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_dimensions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(custom_dimensions \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, dimensions) \u001b[38;5;28;01mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 372\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;66;03m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    375\u001b[0m         activityLogger\u001b[38;5;241m.\u001b[39mactivity_info\u001b[38;5;241m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:665\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_arm_id_or_upload_dependencies(job)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationException, ValidationError) \u001b[38;5;28;01mas\u001b[39;00m ex:  \u001b[38;5;66;03m# pylint: disable=W0718\u001b[39;00m\n\u001b[0;32m--> 665\u001b[0m     \u001b[43mlog_and_raise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m git_props \u001b[38;5;241m=\u001b[39m get_git_properties()\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m# Do not add git props if they already exist in job properties.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# This is for update specifically-- if the user switches branches and tries to update\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;66;03m# their job, the request will fail since the git props will be repopulated.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# MFE does not allow existing properties to be updated, only for new props to be added\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.9/site-packages/azure/ai/ml/_exception_helper.py:337\u001b[0m, in \u001b[0;36mlog_and_raise_error\u001b[0;34m(error, debug, yaml_operation)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m--> 337\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m MlException(message\u001b[38;5;241m=\u001b[39mformatted_error, no_personal_data_message\u001b[38;5;241m=\u001b[39mformatted_error)\n",
      "\u001b[0;31mMlException\u001b[0m: {\n  \"result\": \"Failed\",\n  \"errors\": [\n    {\n      \"message\": \"Required input 'data' for component 'simple_summarization_node' not provided.\",\n      \"path\": \"jobs.simple_summarization_node.inputs.data\",\n      \"value\": null\n    }\n  ]\n}"
     ]
    }
   ],
   "source": [
    "# Submit the pipeline job to your workspace\n",
    "pipeline_job_run = ml_client.jobs.create_or_update(\n",
    "    pipeline_job_def, experiment_name=\"Continuous Monitoring\"\n",
    ")\n",
    "pipeline_job_run\n",
    "\n",
    "ml_client.jobs.stream(pipeline_job_run.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Next step - Setup scheduler for your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from azure.ai.ml.entities import JobSchedule, RecurrenceTrigger, RecurrencePattern\n",
    "from azure.ai.ml.constants import TimeZone\n",
    "\n",
    "schedule_name = \"simple_sdk_create_schedule_recurrence\"\n",
    "schedule_start_time = datetime.utcnow()\n",
    "\n",
    "recurrence_trigger = RecurrenceTrigger(\n",
    "    frequency=\"day\",  # could accept \"hour\", \"minute\", \"day\", \"week\", \"month\"\n",
    "    interval=1,\n",
    "    schedule=RecurrencePattern(hours=10, minutes=[0, 1]),\n",
    "    start_time=schedule_start_time,\n",
    "    time_zone=TimeZone.UTC,\n",
    ")\n",
    "\n",
    "job_schedule = JobSchedule(\n",
    "    name=schedule_name,\n",
    "    trigger=recurrence_trigger,\n",
    "    # Declare the pipeline job to be scheduled. Here we uses the pipeline job created in previous example.\n",
    "    create_job=pipeline_job_def,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Initiate the scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_schedule = ml_client.schedules.begin_create_or_update(\n",
    "    schedule=job_schedule\n",
    ").result()\n",
    "print(job_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To disable or shut down a running scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_schedule = ml_client.schedules.begin_disable(name=schedule_name).result()\n",
    "job_schedule.is_enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Next step - Deploy pipeline to an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import BatchEndpoint, PipelineComponentBatchDeployment\n",
    "\n",
    "# from azure.ai.ml.entities import ModelBatchDeployment, ModelBatchDeploymentSettings, Model, AmlCompute, Data, BatchRetrySettings, CodeConfiguration, Environment, Data\n",
    "# from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
    "\n",
    "\n",
    "endpoint_name = \"hello-my-pipeline-endpoint\"\n",
    "endpoint = BatchEndpoint(\n",
    "    name=endpoint_name,\n",
    "    description=\"A hello world endpoint for pipeline\",\n",
    ")\n",
    "\n",
    "ml_client.batch_endpoints.begin_create_or_update(endpoint).result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
