{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we already have a Python function that calls OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import my_llm_tool\n",
    "\n",
    "deployment_name = \"text-davinci-003\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set up an OpenTelemetry collector\n",
    "\n",
    "Implement a simple collecotr that print the traces to stdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from http.server import BaseHTTPRequestHandler, HTTPServer\n",
    "\n",
    "from opentelemetry.proto.collector.trace.v1.trace_service_pb2 import ExportTraceServiceRequest\n",
    "\n",
    "\n",
    "class OTLPCollector(BaseHTTPRequestHandler):\n",
    "    def do_POST(self):\n",
    "        content_length = int(self.headers['Content-Length'])\n",
    "        post_data = self.rfile.read(content_length)\n",
    "\n",
    "        traces_request = ExportTraceServiceRequest()\n",
    "        traces_request.ParseFromString(post_data)\n",
    "        \n",
    "        print(\"Received a POST request with data:\")\n",
    "        print(traces_request)\n",
    "\n",
    "        self.send_response(200, \"Traces received\")\n",
    "        self.end_headers()\n",
    "        self.wfile.write(b'Data received and printed to stdout.\\n')\n",
    "\n",
    "def run_server(port: int):\n",
    "    server_address = ('', port)\n",
    "    httpd = HTTPServer(server_address, OTLPCollector)\n",
    "    httpd.serve_forever()\n",
    "\n",
    "def start_server(port: int):\n",
    "    server_thread = threading.Thread(target=run_server, args=(port,))\n",
    "    server_thread.daemon = True\n",
    "    server_thread.start()\n",
    "    print(f\"Server started on port {port}. Access http://localhost:{port}/\")\n",
    "    return server_thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke the collecotr service, serving on OTLP port\n",
    "start_server(port=4318)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Trace your application with tracing\n",
    "\n",
    "Call `start_trace()`, and configure the OTLP exporter to above collector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.tracing import start_trace\n",
    "\n",
    "start_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer_provider = trace.get_tracer_provider()\n",
    "otlp_span_exporter = OTLPSpanExporter()\n",
    "tracer_provider.add_span_processor(BatchSpanProcessor(otlp_span_exporter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize traces in the stdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = my_llm_tool(\n",
    "    prompt=\"Write a simple Hello, world! program that displays the greeting message when executed.\",\n",
    "    deployment_name=deployment_name,\n",
    ")\n",
    "result\n",
    "# view the traces under this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracing-rel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
