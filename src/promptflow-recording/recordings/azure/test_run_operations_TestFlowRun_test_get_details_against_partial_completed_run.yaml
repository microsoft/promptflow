interactions:
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000
  response:
    body:
      string: '{"id": "/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000",
        "name": "00000", "type": "Microsoft.MachineLearningServices/workspaces", "location":
        "eastus", "tags": {}, "etag": null, "kind": "Default", "sku": {"name": "Basic",
        "tier": "Basic"}, "properties": {"discoveryUrl": "https://eastus.api.azureml.ms/discovery"}}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '3630'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding,Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.029'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores?count=30&isDefault=true&orderByAsc=false
  response:
    body:
      string: '{"value": [{"id": "/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore",
        "name": "workspaceblobstore", "type": "Microsoft.MachineLearningServices/workspaces/datastores",
        "properties": {"description": null, "tags": null, "properties": null, "isDefault":
        true, "credentials": {"credentialsType": "AccountKey"}, "intellectualProperty":
        null, "subscriptionId": "00000000-0000-0000-0000-000000000000", "resourceGroup":
        "00000", "datastoreType": "AzureBlob", "accountName": "fake_account_name",
        "containerName": "fake-container-name", "endpoint": "core.windows.net", "protocol":
        "https", "serviceDataAccessAuthIdentity": "WorkspaceSystemAssignedIdentity"},
        "systemData": {"createdAt": "2023-04-08T02:53:06.5886442+00:00", "createdBy":
        "779301c0-18b2-4cdc-801b-a0a3368fee0a", "createdByType": "Application", "lastModifiedAt":
        "2023-04-08T02:53:07.521127+00:00", "lastModifiedBy": "779301c0-18b2-4cdc-801b-a0a3368fee0a",
        "lastModifiedByType": "Application"}}]}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '1372'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding,Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.059'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore
  response:
    body:
      string: '{"id": "/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore",
        "name": "workspaceblobstore", "type": "Microsoft.MachineLearningServices/workspaces/datastores",
        "properties": {"description": null, "tags": null, "properties": null, "isDefault":
        true, "credentials": {"credentialsType": "AccountKey"}, "intellectualProperty":
        null, "subscriptionId": "00000000-0000-0000-0000-000000000000", "resourceGroup":
        "00000", "datastoreType": "AzureBlob", "accountName": "fake_account_name",
        "containerName": "fake-container-name", "endpoint": "core.windows.net", "protocol":
        "https", "serviceDataAccessAuthIdentity": "WorkspaceSystemAssignedIdentity"},
        "systemData": {"createdAt": "2023-04-08T02:53:06.5886442+00:00", "createdBy":
        "779301c0-18b2-4cdc-801b-a0a3368fee0a", "createdByType": "Application", "lastModifiedAt":
        "2023-04-08T02:53:07.521127+00:00", "lastModifiedBy": "779301c0-18b2-4cdc-801b-a0a3368fee0a",
        "lastModifiedByType": "Application"}}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '1227'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding,Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.099'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '0'
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: POST
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore/listSecrets
  response:
    body:
      string: '{"secretsType": "AccountKey", "key": "dGhpcyBpcyBmYWtlIGtleQ=="}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '134'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.125'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/xml
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - azsdk-python-storage-blob/12.19.0 Python/3.10.13 (Windows-10-10.0.22631-SP0)
      x-ms-date:
      - Fri, 12 Jan 2024 08:53:29 GMT
      x-ms-version:
      - '2023-11-03'
    method: HEAD
    uri: https://fake_account_name.blob.core.windows.net/fake-container-name/LocalUpload/000000000000000000000000000000000000/numbers.jsonl
  response:
    body:
      string: ''
    headers:
      accept-ranges:
      - bytes
      content-length:
      - '290'
      content-md5:
      - O6LvdPMlN/PM6b7fPh75Jw==
      content-type:
      - application/octet-stream
      last-modified:
      - Tue, 26 Dec 2023 09:52:29 GMT
      server:
      - Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
      vary:
      - Origin
      x-ms-blob-type:
      - BlockBlob
      x-ms-creation-time:
      - Tue, 26 Dec 2023 09:52:29 GMT
      x-ms-meta-name:
      - 229ce463-c199-4588-a9c4-c30e7a4bd25c
      x-ms-meta-upload_status:
      - completed
      x-ms-meta-version:
      - 4cda6a90-97ca-4ad5-b420-5e347369f614
      x-ms-version:
      - '2023-11-03'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/xml
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - azsdk-python-storage-blob/12.19.0 Python/3.10.13 (Windows-10-10.0.22631-SP0)
      x-ms-date:
      - Fri, 12 Jan 2024 08:53:30 GMT
      x-ms-version:
      - '2023-11-03'
    method: HEAD
    uri: https://fake_account_name.blob.core.windows.net/fake-container-name/az-ml-artifacts/000000000000000000000000000000000000/numbers.jsonl
  response:
    body:
      string: ''
    headers:
      server:
      - Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
      transfer-encoding:
      - chunked
      vary:
      - Origin
      x-ms-error-code:
      - BlobNotFound
      x-ms-version:
      - '2023-11-03'
    status:
      code: 404
      message: The specified blob does not exist.
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore
  response:
    body:
      string: '{"id": "/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore",
        "name": "workspaceblobstore", "type": "Microsoft.MachineLearningServices/workspaces/datastores",
        "properties": {"description": null, "tags": null, "properties": null, "isDefault":
        true, "credentials": {"credentialsType": "AccountKey"}, "intellectualProperty":
        null, "subscriptionId": "00000000-0000-0000-0000-000000000000", "resourceGroup":
        "00000", "datastoreType": "AzureBlob", "accountName": "fake_account_name",
        "containerName": "fake-container-name", "endpoint": "core.windows.net", "protocol":
        "https", "serviceDataAccessAuthIdentity": "WorkspaceSystemAssignedIdentity"},
        "systemData": {"createdAt": "2023-04-08T02:53:06.5886442+00:00", "createdBy":
        "779301c0-18b2-4cdc-801b-a0a3368fee0a", "createdByType": "Application", "lastModifiedAt":
        "2023-04-08T02:53:07.521127+00:00", "lastModifiedBy": "779301c0-18b2-4cdc-801b-a0a3368fee0a",
        "lastModifiedByType": "Application"}}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '1227'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding,Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.082'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '0'
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: POST
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore/listSecrets
  response:
    body:
      string: '{"secretsType": "AccountKey", "key": "dGhpcyBpcyBmYWtlIGtleQ=="}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '134'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.097'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/xml
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - azsdk-python-storage-blob/12.19.0 Python/3.10.13 (Windows-10-10.0.22631-SP0)
      x-ms-date:
      - Fri, 12 Jan 2024 08:53:34 GMT
      x-ms-version:
      - '2023-11-03'
    method: HEAD
    uri: https://fake_account_name.blob.core.windows.net/fake-container-name/LocalUpload/000000000000000000000000000000000000/two/flow.dag.yaml
  response:
    body:
      string: ''
    headers:
      accept-ranges:
      - bytes
      content-length:
      - '242'
      content-md5:
      - ySItjr6//pwsGdjLZfgq0A==
      content-type:
      - application/octet-stream
      last-modified:
      - Tue, 26 Dec 2023 09:53:17 GMT
      server:
      - Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
      vary:
      - Origin
      x-ms-blob-type:
      - BlockBlob
      x-ms-creation-time:
      - Tue, 26 Dec 2023 09:52:31 GMT
      x-ms-meta-name:
      - 5b163be8-ab29-4f62-bef0-cd64d56ab269
      x-ms-meta-upload_status:
      - completed
      x-ms-meta-version:
      - '1'
      x-ms-version:
      - '2023-11-03'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/xml
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - azsdk-python-storage-blob/12.19.0 Python/3.10.13 (Windows-10-10.0.22631-SP0)
      x-ms-date:
      - Fri, 12 Jan 2024 08:53:35 GMT
      x-ms-version:
      - '2023-11-03'
    method: HEAD
    uri: https://fake_account_name.blob.core.windows.net/fake-container-name/az-ml-artifacts/000000000000000000000000000000000000/two/flow.dag.yaml
  response:
    body:
      string: ''
    headers:
      server:
      - Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
      transfer-encoding:
      - chunked
      vary:
      - Origin
      x-ms-error-code:
      - BlobNotFound
      x-ms-version:
      - '2023-11-03'
    status:
      code: 404
      message: The specified blob does not exist.
- request:
    body: '{"flowDefinitionDataStoreName": "workspaceblobstore", "flowDefinitionBlobPath":
      "LocalUpload/000000000000000000000000000000000000/two/flow.dag.yaml", "runId":
      "run1", "runDisplayName": "run1", "runExperimentName": "", "batchDataInput":
      {"dataUri": "azureml://datastores/workspaceblobstore/paths/LocalUpload/000000000000000000000000000000000000/numbers.jsonl"},
      "inputsMapping": {"number": "${data.value}"}, "connections": {}, "environmentVariables":
      {}, "runtimeName": "fake-runtime-name", "sessionId": "000000000000000000000000000000000000000000000000",
      "sessionSetupMode": "SystemWait", "flowLineageId": "0000000000000000000000000000000000000000000000000000000000000000",
      "runDisplayNameGenerationType": "UserProvidedMacro"}'
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '783'
      Content-Type:
      - application/json
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: POST
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/submit
  response:
    body:
      string: '"run1"'
    headers:
      connection:
      - keep-alive
      content-length:
      - '38'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      x-content-type-options:
      - nosniff
      x-request-time:
      - '6.387'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "d15d3732-36a4-45ac-b53b-e1fe695b2e77",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.458'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "d15d3732-36a4-45ac-b53b-e1fe695b2e77",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.472'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "d15d3732-36a4-45ac-b53b-e1fe695b2e77",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.262'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "d15d3732-36a4-45ac-b53b-e1fe695b2e77",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.273'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "d15d3732-36a4-45ac-b53b-e1fe695b2e77",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.576'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "d15d3732-36a4-45ac-b53b-e1fe695b2e77",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.422'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "d15d3732-36a4-45ac-b53b-e1fe695b2e77",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.279'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1/childRuns?endIndex=24&startIndex=0
  response:
    body:
      string: '[{"run_id": "run1_2", "status": "Completed", "error": null, "inputs":
        {"number": 2, "line_number": 2}, "output": {"output": 2}, "metrics": null,
        "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:53:58.36557Z",
        "end_time": "2024-01-12T08:53:58.379665Z", "index": 2, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 2}, "output": {"value": 2},
        "start_time": 1705049638.376116, "end_time": 1705049638.377043, "error": null,
        "children": null, "node_name": "mod_two"}], "variant_id": "", "name": "",
        "description": "", "tags": null, "system_metrics": {"duration": 0.014095,
        "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}, "result":
        {"output": 2}, "upload_metrics": false}, {"run_id": "run1_1", "status": "Failed",
        "error": {"message": "Execution failure in ''mod_two'': (Exception) cannot
        mod 2!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_two", "error_type_and_message": "(Exception)
        cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code": "UserError",
        "innerError": {"code": "ToolExecutionError", "innerError": null}, "additionalInfo":
        [{"type": "ToolExecutionErrorDetails", "info": {"type": "Exception", "message":
        "cannot mod 2!", "traceback": "Traceback (most recent call last):\n  File
        \"/mnt/host/service/app/39649/requests/run1/mod_two.py\", line 7, in mod_two\n    raise
        Exception(\"cannot mod 2!\")\nException: cannot mod 2!\n", "filename": "/mnt/host/service/app/39649/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 1, "line_number": 1}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:53:58.382319Z",
        "end_time": "2024-01-12T08:53:58.499971Z", "index": 1, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 1}, "output": null, "start_time":
        1705049638.40109, "end_time": 1705049638.401905, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.117652, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_0", "status":
        "Completed", "error": null, "inputs": {"number": 0, "line_number": 0}, "output":
        {"output": 0}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2024-01-12T08:53:58.298983Z", "end_time": "2024-01-12T08:53:58.326471Z",
        "index": 0, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        0}, "output": {"value": 0}, "start_time": 1705049638.316181, "end_time": 1705049638.316979,
        "error": null, "children": null, "node_name": "mod_two"}], "variant_id": "",
        "name": "", "description": "", "tags": null, "system_metrics": {"duration":
        0.027488, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0},
        "result": {"output": 0}, "upload_metrics": false}, {"run_id": "run1_4", "status":
        "Completed", "error": null, "inputs": {"number": 4, "line_number": 4}, "output":
        {"output": 4}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2024-01-12T08:53:58.445979Z", "end_time": "2024-01-12T08:53:58.472475Z",
        "index": 4, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        4}, "output": {"value": 4}, "start_time": 1705049638.469504, "end_time": 1705049638.470396,
        "error": null, "children": null, "node_name": "mod_two"}], "variant_id": "",
        "name": "", "description": "", "tags": null, "system_metrics": {"duration":
        0.026496, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0},
        "result": {"output": 4}, "upload_metrics": false}, {"run_id": "run1_3", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_two'': (Exception)
        cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_two", "error_type_and_message": "(Exception)
        cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code": "UserError",
        "innerError": {"code": "ToolExecutionError", "innerError": null}, "additionalInfo":
        [{"type": "ToolExecutionErrorDetails", "info": {"type": "Exception", "message":
        "cannot mod 2!", "traceback": "Traceback (most recent call last):\n  File
        \"/mnt/host/service/app/39649/requests/run1/mod_two.py\", line 7, in mod_two\n    raise
        Exception(\"cannot mod 2!\")\nException: cannot mod 2!\n", "filename": "/mnt/host/service/app/39649/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 3, "line_number": 3}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:53:58.440354Z",
        "end_time": "2024-01-12T08:53:58.453661Z", "index": 3, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 3}, "output": null, "start_time":
        1705049638.445455, "end_time": 1705049638.448284, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.013307, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_7", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_two'': (Exception)
        cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_two", "error_type_and_message": "(Exception)
        cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code": "UserError",
        "innerError": {"code": "ToolExecutionError", "innerError": null}, "additionalInfo":
        [{"type": "ToolExecutionErrorDetails", "info": {"type": "Exception", "message":
        "cannot mod 2!", "traceback": "Traceback (most recent call last):\n  File
        \"/mnt/host/service/app/39649/requests/run1/mod_two.py\", line 7, in mod_two\n    raise
        Exception(\"cannot mod 2!\")\nException: cannot mod 2!\n", "filename": "/mnt/host/service/app/39649/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 7, "line_number": 7}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:53:58.508983Z",
        "end_time": "2024-01-12T08:53:58.621053Z", "index": 7, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 7}, "output": null, "start_time":
        1705049638.512829, "end_time": 1705049638.513634, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.11207, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_8", "status":
        "Completed", "error": null, "inputs": {"number": 8, "line_number": 8}, "output":
        {"output": 8}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2024-01-12T08:53:58.529121Z", "end_time": "2024-01-12T08:53:58.538356Z",
        "index": 8, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        8}, "output": {"value": 8}, "start_time": 1705049638.535074, "end_time": 1705049638.535882,
        "error": null, "children": null, "node_name": "mod_two"}], "variant_id": "",
        "name": "", "description": "", "tags": null, "system_metrics": {"duration":
        0.009235, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0},
        "result": {"output": 8}, "upload_metrics": false}, {"run_id": "run1_6", "status":
        "Completed", "error": null, "inputs": {"number": 6, "line_number": 6}, "output":
        {"output": 6}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2024-01-12T08:53:58.481907Z", "end_time": "2024-01-12T08:53:58.489299Z",
        "index": 6, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        6}, "output": {"value": 6}, "start_time": 1705049638.486027, "end_time": 1705049638.487006,
        "error": null, "children": null, "node_name": "mod_two"}], "variant_id": "",
        "name": "", "description": "", "tags": null, "system_metrics": {"duration":
        0.007392, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0},
        "result": {"output": 6}, "upload_metrics": false}, {"run_id": "run1_9", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_two'': (Exception)
        cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_two", "error_type_and_message": "(Exception)
        cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code": "UserError",
        "innerError": {"code": "ToolExecutionError", "innerError": null}, "additionalInfo":
        [{"type": "ToolExecutionErrorDetails", "info": {"type": "Exception", "message":
        "cannot mod 2!", "traceback": "Traceback (most recent call last):\n  File
        \"/mnt/host/service/app/39649/requests/run1/mod_two.py\", line 7, in mod_two\n    raise
        Exception(\"cannot mod 2!\")\nException: cannot mod 2!\n", "filename": "/mnt/host/service/app/39649/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 9, "line_number": 9}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:53:58.529591Z",
        "end_time": "2024-01-12T08:53:58.643284Z", "index": 9, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 9}, "output": null, "start_time":
        1705049638.534116, "end_time": 1705049638.535141, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.113693, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_10", "status":
        "Completed", "error": null, "inputs": {"number": 10, "line_number": 10}, "output":
        {"output": 10}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2024-01-12T08:53:58.567671Z", "end_time": "2024-01-12T08:53:58.573553Z",
        "index": 10, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        10}, "output": {"value": 10}, "start_time": 1705049638.570297, "end_time":
        1705049638.571094, "error": null, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.005882, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": {"output": 10}, "upload_metrics": false}, {"run_id": "run1_11",
        "status": "Failed", "error": {"message": "Execution failure in ''mod_two'':
        (Exception) cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'':
        {error_type_and_message}", "messageParameters": {"node_name": "mod_two", "error_type_and_message":
        "(Exception) cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 2!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n", "filename": "/mnt/host/service/app/39649/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 11, "line_number": 11}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:53:58.623786Z",
        "end_time": "2024-01-12T08:53:58.634409Z", "index": 11, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 11}, "output": null, "start_time":
        1705049638.627165, "end_time": 1705049638.629035, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.010623, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_5", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_two'': (Exception)
        cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_two", "error_type_and_message": "(Exception)
        cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code": "UserError",
        "innerError": {"code": "ToolExecutionError", "innerError": null}, "additionalInfo":
        [{"type": "ToolExecutionErrorDetails", "info": {"type": "Exception", "message":
        "cannot mod 2!", "traceback": "Traceback (most recent call last):\n  File
        \"/mnt/host/service/app/39649/requests/run1/mod_two.py\", line 7, in mod_two\n    raise
        Exception(\"cannot mod 2!\")\nException: cannot mod 2!\n", "filename": "/mnt/host/service/app/39649/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 5, "line_number": 5}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:53:58.478106Z",
        "end_time": "2024-01-12T08:53:58.485903Z", "index": 5, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 5}, "output": null, "start_time":
        1705049638.480935, "end_time": 1705049638.481815, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.007797, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_12", "status":
        "Completed", "error": null, "inputs": {"number": 12, "line_number": 12}, "output":
        {"output": 12}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2024-01-12T08:53:58.857735Z", "end_time": "2024-01-12T08:53:58.8594Z",
        "index": 12, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        12}, "output": {"value": 12}, "start_time": 1705049638.85876, "end_time":
        1705049638.858846, "error": null, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.001665, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": {"output": 12}, "upload_metrics": false}, {"run_id": "run1_13",
        "status": "Failed", "error": {"message": "Execution failure in ''mod_two'':
        (Exception) cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'':
        {error_type_and_message}", "messageParameters": {"node_name": "mod_two", "error_type_and_message":
        "(Exception) cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 2!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n", "filename": "/mnt/host/service/app/39649/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 13, "line_number": 13}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:53:59.081618Z",
        "end_time": "2024-01-12T08:53:59.084304Z", "index": 13, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 13}, "output": null, "start_time":
        1705049639.082711, "end_time": 1705049639.082963, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.002686, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_14", "status":
        "Completed", "error": null, "inputs": {"number": 14, "line_number": 14}, "output":
        {"output": 14}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2024-01-12T08:53:59.095533Z", "end_time": "2024-01-12T08:53:59.097688Z",
        "index": 14, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        14}, "output": {"value": 14}, "start_time": 1705049639.096824, "end_time":
        1705049639.096905, "error": null, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.002155, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": {"output": 14}, "upload_metrics": false}, {"run_id": "run1_15",
        "status": "Failed", "error": {"message": "Execution failure in ''mod_two'':
        (Exception) cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'':
        {error_type_and_message}", "messageParameters": {"node_name": "mod_two", "error_type_and_message":
        "(Exception) cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 2!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n", "filename": "/mnt/host/service/app/39649/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 15, "line_number": 15}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:53:59.11042Z",
        "end_time": "2024-01-12T08:53:59.112899Z", "index": 15, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 15}, "output": null, "start_time":
        1705049639.111395, "end_time": 1705049639.111456, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.002479, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_16", "status":
        "Completed", "error": null, "inputs": {"number": 16, "line_number": 16}, "output":
        {"output": 16}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2024-01-12T08:53:59.122603Z", "end_time": "2024-01-12T08:53:59.125415Z",
        "index": 16, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        16}, "output": {"value": 16}, "start_time": 1705049639.123932, "end_time":
        1705049639.124128, "error": null, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.002812, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": {"output": 16}, "upload_metrics": false}, {"run_id": "run1_17",
        "status": "Failed", "error": {"message": "Execution failure in ''mod_two'':
        (Exception) cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'':
        {error_type_and_message}", "messageParameters": {"node_name": "mod_two", "error_type_and_message":
        "(Exception) cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 2!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n", "filename": "/mnt/host/service/app/39649/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 17, "line_number": 17}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:53:59.201596Z",
        "end_time": "2024-01-12T08:53:59.204779Z", "index": 17, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 17}, "output": null, "start_time":
        1705049639.202943, "end_time": 1705049639.203028, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.003183, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_18", "status":
        "Completed", "error": null, "inputs": {"number": 18, "line_number": 18}, "output":
        {"output": 18}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2024-01-12T08:53:59.216109Z", "end_time": "2024-01-12T08:53:59.21858Z",
        "index": 18, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        18}, "output": {"value": 18}, "start_time": 1705049639.217608, "end_time":
        1705049639.217688, "error": null, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.002471, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": {"output": 18}, "upload_metrics": false}, {"run_id": "run1_19",
        "status": "Failed", "error": {"message": "Execution failure in ''mod_two'':
        (Exception) cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'':
        {error_type_and_message}", "messageParameters": {"node_name": "mod_two", "error_type_and_message":
        "(Exception) cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 2!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n", "filename": "/mnt/host/service/app/39649/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 19, "line_number": 19}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:53:59.231917Z",
        "end_time": "2024-01-12T08:53:59.267557Z", "index": 19, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 19}, "output": null, "start_time":
        1705049639.233619, "end_time": 1705049639.233699, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.03564, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}]'
    headers:
      connection:
      - keep-alive
      content-length:
      - '57297'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.805'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1/childRuns?endIndex=49&startIndex=25
  response:
    body:
      string: '[]'
    headers:
      connection:
      - keep-alive
      content-length:
      - '2'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.746'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore
  response:
    body:
      string: '{"id": "/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore",
        "name": "workspaceblobstore", "type": "Microsoft.MachineLearningServices/workspaces/datastores",
        "properties": {"description": null, "tags": null, "properties": null, "isDefault":
        true, "credentials": {"credentialsType": "AccountKey"}, "intellectualProperty":
        null, "subscriptionId": "00000000-0000-0000-0000-000000000000", "resourceGroup":
        "00000", "datastoreType": "AzureBlob", "accountName": "fake_account_name",
        "containerName": "fake-container-name", "endpoint": "core.windows.net", "protocol":
        "https", "serviceDataAccessAuthIdentity": "WorkspaceSystemAssignedIdentity"},
        "systemData": {"createdAt": "2023-04-08T02:53:06.5886442+00:00", "createdBy":
        "779301c0-18b2-4cdc-801b-a0a3368fee0a", "createdByType": "Application", "lastModifiedAt":
        "2023-04-08T02:53:07.521127+00:00", "lastModifiedBy": "779301c0-18b2-4cdc-801b-a0a3368fee0a",
        "lastModifiedByType": "Application"}}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '1227'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding,Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.077'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '0'
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: POST
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore/listSecrets
  response:
    body:
      string: '{"secretsType": "AccountKey", "key": "dGhpcyBpcyBmYWtlIGtleQ=="}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '134'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.118'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/xml
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - azsdk-python-storage-blob/12.19.0 Python/3.10.13 (Windows-10-10.0.22631-SP0)
      x-ms-date:
      - Fri, 12 Jan 2024 08:55:07 GMT
      x-ms-version:
      - '2023-11-03'
    method: HEAD
    uri: https://fake_account_name.blob.core.windows.net/fake-container-name/LocalUpload/000000000000000000000000000000000000/three/flow.dag.yaml
  response:
    body:
      string: ''
    headers:
      accept-ranges:
      - bytes
      content-length:
      - '248'
      content-md5:
      - B3pfhMEmUOazTzjlKaw6Sw==
      content-type:
      - application/octet-stream
      last-modified:
      - Tue, 26 Dec 2023 10:04:33 GMT
      server:
      - Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
      vary:
      - Origin
      x-ms-blob-type:
      - BlockBlob
      x-ms-creation-time:
      - Tue, 26 Dec 2023 09:54:37 GMT
      x-ms-meta-name:
      - 613ead8f-69ca-4c47-9cba-01f0dd473279
      x-ms-meta-upload_status:
      - completed
      x-ms-meta-version:
      - '1'
      x-ms-version:
      - '2023-11-03'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/xml
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - azsdk-python-storage-blob/12.19.0 Python/3.10.13 (Windows-10-10.0.22631-SP0)
      x-ms-date:
      - Fri, 12 Jan 2024 08:55:08 GMT
      x-ms-version:
      - '2023-11-03'
    method: HEAD
    uri: https://fake_account_name.blob.core.windows.net/fake-container-name/az-ml-artifacts/000000000000000000000000000000000000/three/flow.dag.yaml
  response:
    body:
      string: ''
    headers:
      server:
      - Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
      transfer-encoding:
      - chunked
      vary:
      - Origin
      x-ms-error-code:
      - BlobNotFound
      x-ms-version:
      - '2023-11-03'
    status:
      code: 404
      message: The specified blob does not exist.
- request:
    body: '{"flowDefinitionDataStoreName": "workspaceblobstore", "flowDefinitionBlobPath":
      "LocalUpload/000000000000000000000000000000000000/three/flow.dag.yaml", "runId":
      "run2", "runDisplayName": "run2", "runExperimentName": "", "variantRunId": "run1",
      "batchDataInput": {}, "inputsMapping": {"number": "${run.outputs.output}"},
      "connections": {}, "environmentVariables": {}, "runtimeName": "fake-runtime-name",
      "sessionId": "000000000000000000000000000000000000000000000000", "sessionSetupMode":
      "SystemWait", "flowLineageId": "0000000000000000000000000000000000000000000000000000000000000000",
      "runDisplayNameGenerationType": "UserProvidedMacro"}'
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '734'
      Content-Type:
      - application/json
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: POST
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/submit
  response:
    body:
      string: '"run2"'
    headers:
      connection:
      - keep-alive
      content-length:
      - '38'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      x-content-type-options:
      - nosniff
      x-request-time:
      - '6.653'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "a25bab13-d2d7-4c36-83bf-96979de95507",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.225'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "a25bab13-d2d7-4c36-83bf-96979de95507",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.496'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "a25bab13-d2d7-4c36-83bf-96979de95507",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.245'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "a25bab13-d2d7-4c36-83bf-96979de95507",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.381'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "a25bab13-d2d7-4c36-83bf-96979de95507",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.410'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "a25bab13-d2d7-4c36-83bf-96979de95507",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.408'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "a25bab13-d2d7-4c36-83bf-96979de95507",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.451'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2/childRuns?endIndex=24&startIndex=0
  response:
    body:
      string: '[{"run_id": "run2_0", "status": "Completed", "error": null, "inputs":
        {"number": 0, "line_number": 0}, "output": {"output": 0}, "metrics": null,
        "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:55:31.465237Z",
        "end_time": "2024-01-12T08:55:31.475743Z", "index": 0, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 0}, "output": {"value":
        0}, "start_time": 1705049731.472262, "end_time": 1705049731.473128, "error":
        null, "children": null, "node_name": "mod_three"}], "variant_id": "", "name":
        "", "description": "", "tags": null, "system_metrics": {"duration": 0.010506,
        "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}, "result":
        {"output": 0}, "upload_metrics": false}, {"run_id": "run2_12", "status": "Completed",
        "error": null, "inputs": {"number": 12, "line_number": 12}, "output": {"output":
        12}, "metrics": null, "request": null, "parent_run_id": "run2", "root_run_id":
        "run2", "source_run_id": null, "flow_id": "default_flow_id", "start_time":
        "2024-01-12T08:55:31.656075Z", "end_time": "2024-01-12T08:55:31.661754Z",
        "index": 12, "api_calls": [{"name": "mod_three", "type": "Tool", "inputs":
        {"number": 12}, "output": {"value": 12}, "start_time": 1705049731.658932,
        "end_time": 1705049731.659931, "error": null, "children": null, "node_name":
        "mod_three"}], "variant_id": "", "name": "", "description": "", "tags": null,
        "system_metrics": {"duration": 0.005679, "prompt_tokens": 0, "completion_tokens":
        0, "total_tokens": 0}, "result": {"output": 12}, "upload_metrics": false},
        {"run_id": "run2_2", "status": "Failed", "error": {"message": "Execution failure
        in ''mod_three'': (Exception) cannot mod 3!", "messageFormat": "Execution
        failure in ''{node_name}'': {error_type_and_message}", "messageParameters":
        {"node_name": "mod_three", "error_type_and_message": "(Exception) cannot mod
        3!"}, "referenceCode": "Tool/__pf_main__", "code": "UserError", "innerError":
        {"code": "ToolExecutionError", "innerError": null}, "additionalInfo": [{"type":
        "ToolExecutionErrorDetails", "info": {"type": "Exception", "message": "cannot
        mod 3!", "traceback": "Traceback (most recent call last):\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39649/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_three'': (Exception) cannot mod 3!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null}}}, "inputs": {"number": 2, "line_number": 2}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:55:31.490355Z",
        "end_time": "2024-01-12T08:55:31.575384Z", "index": 2, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 2}, "output": null, "start_time":
        1705049731.497823, "end_time": 1705049731.498797, "error": {"message": "cannot
        mod 3!", "type": "Exception"}, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.085029, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run2_4", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_three'': (Exception)
        cannot mod 3!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_three", "error_type_and_message":
        "(Exception) cannot mod 3!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 3!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39649/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_three'': (Exception) cannot mod 3!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null}}}, "inputs": {"number": 4, "line_number": 4}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:55:31.535972Z",
        "end_time": "2024-01-12T08:55:31.773764Z", "index": 4, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 4}, "output": null, "start_time":
        1705049731.548995, "end_time": 1705049731.550238, "error": {"message": "cannot
        mod 3!", "type": "Exception"}, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.237792, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run2_8", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_three'': (Exception)
        cannot mod 3!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_three", "error_type_and_message":
        "(Exception) cannot mod 3!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 3!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39649/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_three'': (Exception) cannot mod 3!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null}}}, "inputs": {"number": 8, "line_number": 8}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:55:31.559578Z",
        "end_time": "2024-01-12T08:55:31.789137Z", "index": 8, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 8}, "output": null, "start_time":
        1705049731.584465, "end_time": 1705049731.585312, "error": {"message": "cannot
        mod 3!", "type": "Exception"}, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.229559, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run2_6", "status":
        "Completed", "error": null, "inputs": {"number": 6, "line_number": 6}, "output":
        {"output": 6}, "metrics": null, "request": null, "parent_run_id": "run2",
        "root_run_id": "run2", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2024-01-12T08:55:31.555822Z", "end_time": "2024-01-12T08:55:31.564102Z",
        "index": 6, "api_calls": [{"name": "mod_three", "type": "Tool", "inputs":
        {"number": 6}, "output": {"value": 6}, "start_time": 1705049731.561458, "end_time":
        1705049731.562356, "error": null, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.00828, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": {"output": 6}, "upload_metrics": false}, {"run_id": "run2_16",
        "status": "Failed", "error": {"message": "Execution failure in ''mod_three'':
        (Exception) cannot mod 3!", "messageFormat": "Execution failure in ''{node_name}'':
        {error_type_and_message}", "messageParameters": {"node_name": "mod_three",
        "error_type_and_message": "(Exception) cannot mod 3!"}, "referenceCode": "Tool/__pf_main__",
        "code": "UserError", "innerError": {"code": "ToolExecutionError", "innerError":
        null}, "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 3!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39649/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_three'': (Exception) cannot mod 3!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null}}}, "inputs": {"number": 16, "line_number": 16}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:55:31.744907Z",
        "end_time": "2024-01-12T08:55:31.817842Z", "index": 16, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 16}, "output": null, "start_time":
        1705049731.747285, "end_time": 1705049731.747465, "error": {"message": "cannot
        mod 3!", "type": "Exception"}, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.072935, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run2_10", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_three'': (Exception)
        cannot mod 3!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_three", "error_type_and_message":
        "(Exception) cannot mod 3!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 3!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39649/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_three'': (Exception) cannot mod 3!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null}}}, "inputs": {"number": 10, "line_number": 10}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:55:31.59072Z",
        "end_time": "2024-01-12T08:55:31.604864Z", "index": 10, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 10}, "output": null, "start_time":
        1705049731.59849, "end_time": 1705049731.600113, "error": {"message": "cannot
        mod 3!", "type": "Exception"}, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.014144, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run2_14", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_three'': (Exception)
        cannot mod 3!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_three", "error_type_and_message":
        "(Exception) cannot mod 3!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 3!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39649/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_three'': (Exception) cannot mod 3!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null}}}, "inputs": {"number": 14, "line_number": 14}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2024-01-12T08:55:31.736285Z",
        "end_time": "2024-01-12T08:55:31.745117Z", "index": 14, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 14}, "output": null, "start_time":
        1705049731.739545, "end_time": 1705049731.740525, "error": {"message": "cannot
        mod 3!", "type": "Exception"}, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.008832, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run2_18", "status":
        "Completed", "error": null, "inputs": {"number": 18, "line_number": 18}, "output":
        {"output": 18}, "metrics": null, "request": null, "parent_run_id": "run2",
        "root_run_id": "run2", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2024-01-12T08:55:31.890045Z", "end_time": "2024-01-12T08:55:31.891993Z",
        "index": 18, "api_calls": [{"name": "mod_three", "type": "Tool", "inputs":
        {"number": 18}, "output": {"value": 18}, "start_time": 1705049731.891255,
        "end_time": 1705049731.891333, "error": null, "children": null, "node_name":
        "mod_three"}], "variant_id": "", "name": "", "description": "", "tags": null,
        "system_metrics": {"duration": 0.001948, "prompt_tokens": 0, "completion_tokens":
        0, "total_tokens": 0}, "result": {"output": 18}, "upload_metrics": false}]'
    headers:
      connection:
      - keep-alive
      content-length:
      - '32873'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.930'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2/childRuns?endIndex=49&startIndex=25
  response:
    body:
      string: '[]'
    headers:
      connection:
      - keep-alive
      content-length:
      - '2'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.727'
    status:
      code: 200
      message: OK
- request:
    body: '{"runId": "run1", "selectRunMetadata": true, "selectRunDefinition": true,
      "selectJobSpecification": true}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '137'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.31.0
    method: POST
    uri: https://eastus.api.azureml.ms/history/v1.0/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/rundata
  response:
    body:
      string: '{"runMetadata": {"runNumber": 1705049621, "rootRunId": "run1", "createdUtc":
        "2024-01-12T08:53:41.7311265+00:00", "createdBy": {"userObjectId": "00000000-0000-0000-0000-000000000000",
        "userPuId": null, "userIdp": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userAltSecId": null, "userIss": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userTenantId": "00000000-0000-0000-0000-000000000000", "userName": "4cbd0e2e-aae4-4099-b4ba-94d3a4910587",
        "upn": null}, "userId": "00000000-0000-0000-0000-000000000000", "token": null,
        "tokenExpiryTimeUtc": null, "error": {"error": {"code": "UserError", "severity":
        null, "message": "Execution failure in ''mod_two'': (Exception) cannot mod
        2!", "messageFormat": "{\"totalChildRuns\": 20, \"userErrorChildRuns\": 10,
        \"systemErrorChildRuns\": 0, \"errorDetails\": [{\"code\": \"UserError/ToolExecutionError\",
        \"messageFormat\": \"Execution failure in ''{node_name}'': {error_type_and_message}\",
        \"count\": 10}]}", "messageParameters": {"node_name": "mod_two", "error_type_and_message":
        "(Exception) cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "detailsUri":
        null, "target": null, "details": [], "innerError": {"code": "ToolExecutionError",
        "innerError": null}, "debugInfo": {"type": "ToolExecutionError", "message":
        "Execution failure in ''mod_two'': (Exception) cannot mod 2!", "stackTrace":
        "\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null, "data": null, "errorResponse": null}, "data": null, "errorResponse":
        null}, "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 2!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n", "filename": "/mnt/host/service/app/39649/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}]}, "correlation": null, "environment": null,
        "location": null, "time": "2024-01-12T08:54:32.157997+00:00", "componentName":
        "promptflow-runtime/20231204.v4 Designer/1.0 promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0) promptflow/1.2.0rc1"}, "warnings":
        null, "revision": 7, "statusRevision": 3, "runUuid": "08457cff-a0cf-4b93-8b58-24b47e6e2f06",
        "parentRunUuid": null, "rootRunUuid": "08457cff-a0cf-4b93-8b58-24b47e6e2f06",
        "lastStartTimeUtc": null, "currentComputeTime": null, "computeDuration": "00:00:34.5206194",
        "effectiveStartTimeUtc": null, "lastModifiedBy": {"userObjectId": "00000000-0000-0000-0000-000000000000",
        "userPuId": null, "userIdp": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userAltSecId": null, "userIss": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userTenantId": "00000000-0000-0000-0000-000000000000", "userName": "18a66f5f-dbdf-4c17-9dd7-1634712a9cbe",
        "upn": null}, "lastModifiedUtc": "2024-01-12T08:54:31.4291957+00:00", "duration":
        "00:00:34.5206194", "cancelationReason": null, "currentAttemptId": 1, "runId":
        "run1", "parentRunId": null, "experimentId": "f65cb39a-0d28-4b06-9ef9-b962ed9df8d0",
        "status": "Completed", "startTimeUtc": "2024-01-12T08:53:57.8643652+00:00",
        "endTimeUtc": "2024-01-12T08:54:32.3849846+00:00", "scheduleId": null, "displayName":
        "run1", "name": null, "dataContainerId": "dcid.run1", "description": null,
        "hidden": false, "runType": "azureml.promptflow.FlowRun", "runTypeV2": {"orchestrator":
        null, "traits": [], "attribution": "PromptFlow", "computeType": "AmlcDsi"},
        "properties": {"azureml.promptflow.runtime_name": "test-runtime-ci", "azureml.promptflow.runtime_version":
        "20231204.v4", "azureml.promptflow.definition_file_name": "flow.dag.yaml",
        "azureml.promptflow.session_id": "357876c0a66919ba9791ba9723d3eb045181f10b65c806ea",
        "azureml.promptflow.flow_lineage_id": "3df9ed48cf83e1a38799b0a91f06e0825173b507d07391d1d91ec0253c1cda5c",
        "azureml.promptflow.flow_definition_datastore_name": "workspaceblobstore",
        "azureml.promptflow.flow_definition_blob_path": "LocalUpload/ceb856845f8689bdee2da5a26bd95bab/two/flow.dag.yaml",
        "azureml.promptflow.input_data": "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl",
        "azureml.promptflow.inputs_mapping": "{\"number\":\"${data.value}\"}", "_azureml.evaluation_run":
        "promptflow.BatchRun", "azureml.promptflow.snapshot_id": "d15d3732-36a4-45ac-b53b-e1fe695b2e77",
        "azureml.promptflow.total_tokens": "0", "_azureml.evaluate_artifacts": "[{\"path\":
        \"instance_results.jsonl\", \"type\": \"table\"}]"}, "parameters": {}, "actionUris":
        {}, "scriptName": null, "target": null, "uniqueChildRunComputeTargets": [],
        "tags": {}, "settings": {}, "services": {}, "inputDatasets": [], "outputDatasets":
        [], "runDefinition": null, "jobSpecification": null, "primaryMetricName":
        null, "createdFrom": null, "cancelUri": null, "completeUri": null, "diagnosticsUri":
        null, "computeRequest": null, "compute": null, "retainForLifetimeOfWorkspace":
        false, "queueingInfo": null, "inputs": null, "outputs": {"debug_info": {"assetId":
        "azureml://locations/eastus/workspaces/00000/data/azureml_run1_output_data_debug_info/versions/1",
        "type": "UriFolder"}, "flow_outputs": {"assetId": "azureml://locations/eastus/workspaces/00000/data/azureml_run1_output_data_flow_outputs/versions/1",
        "type": "UriFolder"}}}, "runDefinition": null, "jobSpecification": null, "systemSettings":
        null}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '9907'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.053'
    status:
      code: 200
      message: OK
- request:
    body: '{"runId": "run2", "selectRunMetadata": true, "selectRunDefinition": true,
      "selectJobSpecification": true}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '137'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.31.0
    method: POST
    uri: https://eastus.api.azureml.ms/history/v1.0/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/rundata
  response:
    body:
      string: '{"runMetadata": {"runNumber": 1705049714, "rootRunId": "run2", "createdUtc":
        "2024-01-12T08:55:14.362818+00:00", "createdBy": {"userObjectId": "00000000-0000-0000-0000-000000000000",
        "userPuId": null, "userIdp": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userAltSecId": null, "userIss": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userTenantId": "00000000-0000-0000-0000-000000000000", "userName": "4cbd0e2e-aae4-4099-b4ba-94d3a4910587",
        "upn": null}, "userId": "00000000-0000-0000-0000-000000000000", "token": null,
        "tokenExpiryTimeUtc": null, "error": {"error": {"code": "UserError", "severity":
        null, "message": "Execution failure in ''mod_three'': (Exception) cannot mod
        3!", "messageFormat": "{\"totalChildRuns\": 10, \"userErrorChildRuns\": 6,
        \"systemErrorChildRuns\": 0, \"errorDetails\": [{\"code\": \"UserError/ToolExecutionError\",
        \"messageFormat\": \"Execution failure in ''{node_name}'': {error_type_and_message}\",
        \"count\": 6}]}", "messageParameters": {"node_name": "mod_three", "error_type_and_message":
        "(Exception) cannot mod 3!"}, "referenceCode": "Tool/__pf_main__", "detailsUri":
        null, "target": null, "details": [], "innerError": {"code": "ToolExecutionError",
        "innerError": null}, "debugInfo": {"type": "ToolExecutionError", "message":
        "Execution failure in ''mod_three'': (Exception) cannot mod 3!", "stackTrace":
        "\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null, "data": null, "errorResponse": null}, "data": null, "errorResponse":
        null}, "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 3!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39649/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}]}, "correlation": null, "environment":
        null, "location": null, "time": "2024-01-12T08:56:05.377066+00:00", "componentName":
        "promptflow-runtime/20231204.v4 Designer/1.0 promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0) promptflow/1.2.0rc1"}, "warnings":
        null, "revision": 7, "statusRevision": 3, "runUuid": "b80a9962-ed21-4dfb-85b0-2548b1649f39",
        "parentRunUuid": null, "rootRunUuid": "b80a9962-ed21-4dfb-85b0-2548b1649f39",
        "lastStartTimeUtc": null, "currentComputeTime": null, "computeDuration": "00:00:34.5231338",
        "effectiveStartTimeUtc": null, "lastModifiedBy": {"userObjectId": "00000000-0000-0000-0000-000000000000",
        "userPuId": null, "userIdp": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userAltSecId": null, "userIss": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userTenantId": "00000000-0000-0000-0000-000000000000", "userName": "18a66f5f-dbdf-4c17-9dd7-1634712a9cbe",
        "upn": null}, "lastModifiedUtc": "2024-01-12T08:56:04.2209326+00:00", "duration":
        "00:00:34.5231338", "cancelationReason": null, "currentAttemptId": 1, "runId":
        "run2", "parentRunId": null, "experimentId": "3a00e270-37b9-49be-a74e-ac675487979e",
        "status": "Completed", "startTimeUtc": "2024-01-12T08:55:31.0651672+00:00",
        "endTimeUtc": "2024-01-12T08:56:05.588301+00:00", "scheduleId": null, "displayName":
        "run2", "name": null, "dataContainerId": "dcid.run2", "description": null,
        "hidden": false, "runType": "azureml.promptflow.FlowRun", "runTypeV2": {"orchestrator":
        null, "traits": [], "attribution": "PromptFlow", "computeType": "AmlcDsi"},
        "properties": {"azureml.promptflow.runtime_name": "test-runtime-ci", "azureml.promptflow.runtime_version":
        "20231204.v4", "azureml.promptflow.definition_file_name": "flow.dag.yaml",
        "azureml.promptflow.session_id": "c9399af7028d644e85f3624a0b026432068432621519ab8f",
        "azureml.promptflow.flow_lineage_id": "77a36a2606b22ee30674046884962374e57e822acdeccac7750905d98e944580",
        "azureml.promptflow.flow_definition_datastore_name": "workspaceblobstore",
        "azureml.promptflow.flow_definition_blob_path": "LocalUpload/f0722e3fb27e86b101670dbb5e85554c/three/flow.dag.yaml",
        "azureml.promptflow.input_run_id": "run1", "azureml.promptflow.inputs_mapping":
        "{\"number\":\"${run.outputs.output}\"}", "_azureml.evaluation_run": "promptflow.BatchRun",
        "azureml.promptflow.snapshot_id": "a25bab13-d2d7-4c36-83bf-96979de95507",
        "azureml.promptflow.total_tokens": "0", "_azureml.evaluate_artifacts": "[{\"path\":
        \"instance_results.jsonl\", \"type\": \"table\"}]"}, "parameters": {}, "actionUris":
        {}, "scriptName": null, "target": null, "uniqueChildRunComputeTargets": [],
        "tags": {}, "settings": {}, "services": {}, "inputDatasets": [], "outputDatasets":
        [], "runDefinition": null, "jobSpecification": null, "primaryMetricName":
        null, "createdFrom": null, "cancelUri": null, "completeUri": null, "diagnosticsUri":
        null, "computeRequest": null, "compute": null, "retainForLifetimeOfWorkspace":
        false, "queueingInfo": null, "inputs": null, "outputs": {"debug_info": {"assetId":
        "azureml://locations/eastus/workspaces/00000/data/azureml_run2_output_data_debug_info/versions/1",
        "type": "UriFolder"}, "flow_outputs": {"assetId": "azureml://locations/eastus/workspaces/00000/data/azureml_run2_output_data_flow_outputs/versions/1",
        "type": "UriFolder"}}}, "runDefinition": null, "jobSpecification": null, "systemSettings":
        null}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '9865'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.037'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1/logContent
  response:
    body:
      string: '"2024-01-12 08:53:45 +0000      49 promptflow-runtime INFO     [run1]
        Receiving v2 bulk run request e51d6436-3ed9-4576-b848-1967710c148c: {\"flow_id\":
        \"run1\", \"flow_run_id\": \"run1\", \"flow_source\": {\"flow_source_type\":
        1, \"flow_source_info\": {\"snapshot_id\": \"d15d3732-36a4-45ac-b53b-e1fe695b2e77\"},
        \"flow_dag_file\": \"flow.dag.yaml\"}, \"log_path\": \"https://promptfloweast4063704120.blob.core.windows.net/azureml/ExperimentRun/dcid.run1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=**data_scrubbed**&skoid=55b92eba-d7c7-4afd-ab76-7bb1cd345283&sktid=00000000-0000-0000-0000-000000000000&skt=2024-01-12T08%3A43%3A40Z&ske=2024-01-13T16%3A53%3A40Z&sks=b&skv=2019-07-07&st=2024-01-12T08%3A43%3A44Z&se=2024-01-12T16%3A53%3A44Z&sp=rcw\",
        \"app_insights_instrumentation_key\": \"InstrumentationKey=**data_scrubbed**;IngestionEndpoint=https://eastus-6.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/\",
        \"data_inputs\": {\"data\": \"azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl\"},
        \"inputs_mapping\": {\"number\": \"${data.value}\"}, \"azure_storage_setting\":
        {\"azure_storage_mode\": 1, \"storage_account_name\": \"promptfloweast4063704120\",
        \"blob_container_name\": \"azureml-blobstore-3e123da1-f9a5-4c91-9234-8d9ffbb39ff5\",
        \"flow_artifacts_root_path\": \"promptflow/PromptFlowArtifacts/run1\", \"blob_container_sas_token\":
        \"?sv=2019-07-07&sr=c&sig=**data_scrubbed**&skoid=55b92eba-d7c7-4afd-ab76-7bb1cd345283&sktid=00000000-0000-0000-0000-000000000000&skt=2024-01-12T08%3A53%3A45Z&ske=2024-01-19T08%3A53%3A45Z&sks=b&skv=2019-07-07&se=2024-01-19T08%3A53%3A45Z&sp=racwl\",
        \"output_datastore_name\": \"workspaceblobstore\"}}\n2024-01-12 08:53:45 +0000      49
        promptflow-runtime INFO     Runtime version: 20231204.v4. PromptFlow version:
        1.2.0rc1\n2024-01-12 08:53:45 +0000      49 promptflow-runtime INFO     Updating
        run1 to Status.Preparing...\n2024-01-12 08:53:45 +0000      49 promptflow-runtime
        INFO     Downloading snapshot to /mnt/host/service/app/39649/requests/run1\n2024-01-12
        08:53:45 +0000      49 promptflow-runtime INFO     Get snapshot sas url for
        d15d3732-36a4-45ac-b53b-e1fe695b2e77...\n2024-01-12 08:53:52 +0000      49
        promptflow-runtime INFO     Downloading snapshot d15d3732-36a4-45ac-b53b-e1fe695b2e77
        from uri https://promptfloweast4063704120.blob.core.windows.net/snapshotzips/promptflow-eastus:3e123da1-f9a5-4c91-9234-8d9ffbb39ff5:snapshotzip/d15d3732-36a4-45ac-b53b-e1fe695b2e77.zip...\n2024-01-12
        08:53:52 +0000      49 promptflow-runtime INFO     Downloaded file /mnt/host/service/app/39649/requests/run1/d15d3732-36a4-45ac-b53b-e1fe695b2e77.zip
        with size 509 for snapshot d15d3732-36a4-45ac-b53b-e1fe695b2e77.\n2024-01-12
        08:53:52 +0000      49 promptflow-runtime INFO     Download snapshot d15d3732-36a4-45ac-b53b-e1fe695b2e77
        completed.\n2024-01-12 08:53:52 +0000      49 promptflow-runtime INFO     Successfully
        download snapshot to /mnt/host/service/app/39649/requests/run1\n2024-01-12
        08:53:52 +0000      49 promptflow-runtime INFO     About to execute a python
        flow.\n2024-01-12 08:53:52 +0000      49 promptflow-runtime INFO     Use spawn
        method to start child process.\n2024-01-12 08:53:52 +0000      49 promptflow-runtime
        INFO     Starting to check process 6280 status for run run1\n2024-01-12 08:53:52
        +0000      49 promptflow-runtime INFO     Start checking run status for run
        run1\n2024-01-12 08:53:56 +0000    6280 promptflow-runtime INFO     [49--6280]
        Start processing flowV2......\n2024-01-12 08:53:56 +0000    6280 promptflow-runtime
        INFO     Runtime version: 20231204.v4. PromptFlow version: 1.2.0rc1\n2024-01-12
        08:53:56 +0000    6280 promptflow-runtime INFO     Setting mlflow tracking
        uri...\n2024-01-12 08:53:56 +0000    6280 promptflow-runtime INFO     Validating
        ''AzureML Data Scientist'' user authentication...\n2024-01-12 08:53:56 +0000    6280
        promptflow-runtime INFO     Successfully validated ''AzureML Data Scientist''
        user authentication.\n2024-01-12 08:53:56 +0000    6280 promptflow-runtime
        INFO     Using AzureMLRunStorageV2\n2024-01-12 08:53:56 +0000    6280 promptflow-runtime
        INFO     Setting mlflow tracking uri to ''azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/promptflow-eastus''\n2024-01-12
        08:53:56 +0000    6280 promptflow-runtime INFO     Initialized blob service
        client for AzureMLRunTracker.\n2024-01-12 08:53:56 +0000    6280 promptflow-runtime
        INFO     Setting mlflow tracking uri to ''azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/promptflow-eastus''\n2024-01-12
        08:53:57 +0000    6280 promptflow-runtime INFO     Resolve data from url finished
        in 0.6618335284292698 seconds\n2024-01-12 08:53:57 +0000    6280 promptflow-runtime
        INFO     Starting the aml run ''run1''...\n2024-01-12 08:53:58 +0000    6280
        execution.bulk     INFO     Using fork, process count: 16\n2024-01-12 08:53:58
        +0000    6335 execution.bulk     INFO     Process 6335 started.\n2024-01-12
        08:53:58 +0000    6351 execution.bulk     INFO     Process 6351 started.\n2024-01-12
        08:53:58 +0000    6345 execution.bulk     INFO     Process 6345 started.\n2024-01-12
        08:53:58 +0000    6280 execution.bulk     INFO     Process name: ForkProcess-62:2,
        Process id: 6335, Line number: 0 start execution.\n2024-01-12 08:53:58 +0000    6379
        execution.bulk     INFO     Process 6379 started.\n2024-01-12 08:53:58 +0000    6382
        execution.bulk     INFO     Process 6382 started.\n2024-01-12 08:53:58 +0000    6387
        execution.bulk     INFO     Process 6387 started.\n2024-01-12 08:53:58 +0000    6351
        execution          ERROR    Node mod_two in line 1 failed. Exception: Execution
        failure in ''mod_two'': (Exception) cannot mod 2!.\nTraceback (most recent
        call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_two'': (Exception) cannot mod 2!\n2024-01-12 08:53:58 +0000    6362
        execution.bulk     INFO     Process 6362 started.\n2024-01-12 08:53:58 +0000    6369
        execution.bulk     INFO     Process 6369 started.\n2024-01-12 08:53:58 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:6, Process id: 6351,
        Line number: 1 start execution.\n2024-01-12 08:53:58 +0000    6351 execution          ERROR    Execution
        of one node has failed. Cancelling all running nodes: mod_two.\n2024-01-12
        08:53:58 +0000    6367 execution.bulk     INFO     Process 6367 started.\n2024-01-12
        08:53:58 +0000    6398 execution.bulk     INFO     Process 6398 started.\n2024-01-12
        08:53:58 +0000    6280 execution.bulk     INFO     Process name: ForkProcess-62:3,
        Process id: 6345, Line number: 2 start execution.\n2024-01-12 08:53:58 +0000    6422
        execution.bulk     INFO     Process 6422 started.\n2024-01-12 08:53:58 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:8, Process id: 6379,
        Line number: 3 start execution.\n2024-01-12 08:53:58 +0000    6369 execution          ERROR    Node
        mod_two in line 7 failed. Exception: Execution failure in ''mod_two'': (Exception)
        cannot mod 2!.\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_two'': (Exception) cannot mod 2!\n2024-01-12 08:53:58 +0000    6391
        execution.bulk     INFO     Process 6391 started.\n2024-01-12 08:53:58 +0000    6367
        execution          ERROR    Node mod_two in line 9 failed. Exception: Execution
        failure in ''mod_two'': (Exception) cannot mod 2!.\nTraceback (most recent
        call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_two'': (Exception) cannot mod 2!\n2024-01-12 08:53:58 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:9, Process id: 6382,
        Line number: 4 start execution.\n2024-01-12 08:53:58 +0000    6369 execution          ERROR    Execution
        of one node has failed. Cancelling all running nodes: mod_two.\n2024-01-12
        08:53:58 +0000    6439 execution.bulk     INFO     Process 6439 started.\n2024-01-12
        08:53:58 +0000    6280 execution.bulk     INFO     Process name: ForkProcess-62:10,
        Process id: 6387, Line number: 5 start execution.\n2024-01-12 08:53:58 +0000    6367
        execution          ERROR    Execution of one node has failed. Cancelling all
        running nodes: mod_two.\n2024-01-12 08:53:58 +0000    6403 execution.bulk     INFO     Process
        6403 started.\n2024-01-12 08:53:58 +0000    6280 execution.bulk     INFO     Process
        name: ForkProcess-62:7, Process id: 6362, Line number: 6 start execution.\n2024-01-12
        08:53:58 +0000    6280 execution.bulk     INFO     Process name: ForkProcess-62:4,
        Process id: 6369, Line number: 7 start execution.\n2024-01-12 08:53:58 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:11, Process id: 6398,
        Line number: 8 start execution.\n2024-01-12 08:53:58 +0000    6280 execution.bulk     INFO     Process
        name: ForkProcess-62:5, Process id: 6367, Line number: 9 start execution.\n2024-01-12
        08:53:58 +0000    6280 execution.bulk     INFO     Process name: ForkProcess-62:14,
        Process id: 6422, Line number: 10 start execution.\n2024-01-12 08:53:58 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:12, Process id: 6391,
        Line number: 11 start execution.\n2024-01-12 08:53:58 +0000    6280 execution.bulk     INFO     Process
        name: ForkProcess-62:3, Process id: 6345, Line number: 2 completed.\n2024-01-12
        08:53:58 +0000    6280 execution.bulk     INFO     Process name: ForkProcess-62:6,
        Process id: 6351, Line number: 1 completed.\n2024-01-12 08:53:58 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:9, Process id: 6382,
        Line number: 4 completed.\n2024-01-12 08:53:58 +0000    6280 execution.bulk     INFO     Process
        name: ForkProcess-62:8, Process id: 6379, Line number: 3 completed.\n2024-01-12
        08:53:58 +0000    6280 execution.bulk     INFO     Process name: ForkProcess-62:2,
        Process id: 6335, Line number: 0 completed.\n2024-01-12 08:53:58 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:4, Process id: 6369,
        Line number: 7 completed.\n2024-01-12 08:53:58 +0000    6280 execution.bulk     INFO     Finished
        6 / 20 lines.\n2024-01-12 08:53:58 +0000    6280 execution.bulk     INFO     Finished
        6 / 20 lines.\n2024-01-12 08:53:58 +0000    6280 execution.bulk     INFO     Process
        name: ForkProcess-62:7, Process id: 6362, Line number: 6 completed.\n2024-01-12
        08:53:58 +0000    6280 execution.bulk     INFO     Process name: ForkProcess-62:11,
        Process id: 6398, Line number: 8 completed.\n2024-01-12 08:53:58 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:5, Process id: 6367,
        Line number: 9 completed.\n2024-01-12 08:53:58 +0000    6280 execution.bulk     INFO     Process
        name: ForkProcess-62:9, Process id: 6382, Line number: 12 start execution.\n2024-01-12
        08:53:58 +0000    6280 execution.bulk     INFO     Process name: ForkProcess-62:14,
        Process id: 6422, Line number: 10 completed.\n2024-01-12 08:53:58 +0000    6280
        execution.bulk     INFO     Finished 10 / 20 lines.\n2024-01-12 08:53:58 +0000    6280
        execution.bulk     INFO     Finished 10 / 20 lines.\n2024-01-12 08:53:58 +0000    6280
        execution.bulk     INFO     Finished 10 / 20 lines.\n2024-01-12 08:53:58 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:12, Process id: 6391,
        Line number: 11 completed.\n2024-01-12 08:53:58 +0000    6280 execution.bulk     INFO     Average
        execution time for completed lines: 0.11 seconds. Estimated time for incomplete
        lines: 1.54 seconds.\n2024-01-12 08:53:58 +0000    6280 execution.bulk     INFO     Process
        name: ForkProcess-62:10, Process id: 6387, Line number: 5 completed.\n2024-01-12
        08:53:58 +0000    6280 execution.bulk     INFO     Average execution time
        for completed lines: 0.11 seconds. Estimated time for incomplete lines: 1.54
        seconds.\n2024-01-12 08:53:58 +0000    6280 execution.bulk     INFO     Finished
        12 / 20 lines.\n2024-01-12 08:53:58 +0000    6280 execution.bulk     INFO     Finished
        12 / 20 lines.\n2024-01-12 08:53:58 +0000    6280 execution.bulk     INFO     Finished
        12 / 20 lines.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Finished
        12 / 20 lines.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.7 seconds.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.7 seconds.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.7 seconds.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Process
        name: ForkProcess-62:9, Process id: 6382, Line number: 12 completed.\n2024-01-12
        08:53:59 +0000    6369 execution          ERROR    Node mod_two in line 19
        failed. Exception: Execution failure in ''mod_two'': (Exception) cannot mod
        2!.\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_two'': (Exception) cannot mod 2!\n2024-01-12 08:53:59 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:12, Process id: 6391,
        Line number: 13 start execution.\n2024-01-12 08:53:59 +0000    6369 execution          ERROR    Execution
        of one node has failed. Cancelling all running nodes: mod_two.\n2024-01-12
        08:53:59 +0000    6280 execution.bulk     INFO     Process name: ForkProcess-62:3,
        Process id: 6345, Line number: 14 start execution.\n2024-01-12 08:53:59 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:10, Process id: 6387,
        Line number: 15 start execution.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Process
        name: ForkProcess-62:6, Process id: 6351, Line number: 16 start execution.\n2024-01-12
        08:53:59 +0000    6280 execution.bulk     INFO     Average execution time
        for completed lines: 0.07 seconds. Estimated time for incomplete lines: 0.56
        seconds.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.56 seconds.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.56 seconds.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.56 seconds.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Process
        name: ForkProcess-62:8, Process id: 6379, Line number: 17 start execution.\n2024-01-12
        08:53:59 +0000    6280 execution.bulk     INFO     Process name: ForkProcess-62:2,
        Process id: 6335, Line number: 18 start execution.\n2024-01-12 08:53:59 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:4, Process id: 6369,
        Line number: 19 start execution.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Process
        name: ForkProcess-62:12, Process id: 6391, Line number: 13 completed.\n2024-01-12
        08:53:59 +0000    6280 execution.bulk     INFO     Process name: ForkProcess-62:3,
        Process id: 6345, Line number: 14 completed.\n2024-01-12 08:53:59 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:10, Process id: 6387,
        Line number: 15 completed.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Process
        name: ForkProcess-62:6, Process id: 6351, Line number: 16 completed.\n2024-01-12
        08:53:59 +0000    6280 execution.bulk     INFO     Process name: ForkProcess-62:8,
        Process id: 6379, Line number: 17 completed.\n2024-01-12 08:53:59 +0000    6280
        execution.bulk     INFO     Finished 18 / 20 lines.\n2024-01-12 08:53:59 +0000    6280
        execution.bulk     INFO     Process name: ForkProcess-62:2, Process id: 6335,
        Line number: 18 completed.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Process
        name: ForkProcess-62:4, Process id: 6369, Line number: 19 completed.\n2024-01-12
        08:53:59 +0000    6280 execution.bulk     INFO     Finished 20 / 20 lines.\n2024-01-12
        08:53:59 +0000    6280 execution.bulk     INFO     Finished 20 / 20 lines.\n2024-01-12
        08:53:59 +0000    6280 execution.bulk     INFO     Finished 20 / 20 lines.\n2024-01-12
        08:53:59 +0000    6280 execution.bulk     INFO     Average execution time
        for completed lines: 0.07 seconds. Estimated time for incomplete lines: 0.14
        seconds.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Finished
        20 / 20 lines.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Finished
        20 / 20 lines.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.0 seconds.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.0 seconds.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.0 seconds.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.0 seconds.\n2024-01-12 08:53:59 +0000    6280 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.0 seconds.\n2024-01-12 08:54:29 +0000    6280 execution          ERROR    10/20
        flow run failed, indexes: [1,3,5,7,9,11,13,15,17,19], exception of index 1:
        Execution failure in ''mod_two'': (Exception) cannot mod 2!\n2024-01-12 08:54:31
        +0000    6280 execution.bulk     INFO     Upload status summary metrics for
        run run1 finished in 1.6117610009387136 seconds\n2024-01-12 08:54:31 +0000    6280
        promptflow-runtime INFO     Successfully write run properties {\"azureml.promptflow.total_tokens\":
        0, \"_azureml.evaluate_artifacts\": \"[{\\\"path\\\": \\\"instance_results.jsonl\\\",
        \\\"type\\\": \\\"table\\\"}]\"} with run id ''run1''\n2024-01-12 08:54:31
        +0000    6280 execution.bulk     INFO     Upload RH properties for run run1
        finished in 0.08309784904122353 seconds\n2024-01-12 08:54:31 +0000    6280
        promptflow-runtime INFO     Creating unregistered output Asset for Run run1...\n2024-01-12
        08:54:31 +0000    6280 promptflow-runtime INFO     Created debug_info Asset:
        azureml://locations/eastus/workspaces/00000/data/azureml_run1_output_data_debug_info/versions/1\n2024-01-12
        08:54:31 +0000    6280 promptflow-runtime INFO     Creating unregistered output
        Asset for Run run1...\n2024-01-12 08:54:31 +0000    6280 promptflow-runtime
        INFO     Created flow_outputs output Asset: azureml://locations/eastus/workspaces/00000/data/azureml_run1_output_data_flow_outputs/versions/1\n2024-01-12
        08:54:31 +0000    6280 promptflow-runtime INFO     Creating Artifact for Run
        run1...\n2024-01-12 08:54:32 +0000    6280 promptflow-runtime INFO     Created
        instance_results.jsonl Artifact.\n2024-01-12 08:54:32 +0000    6280 promptflow-runtime
        INFO     Patching run1...\n2024-01-12 08:54:32 +0000    6280 promptflow-runtime
        WARNING  [run1] Run failed. Execution stackTrace: Traceback (most recent call
        last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  [REDACTED:
        External StackTrace]\n\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  [REDACTED:
        External StackTrace]\n\n2024-01-12 08:54:32 +0000    6280 promptflow-runtime
        INFO     Ending the aml run ''run1'' with status ''Completed''...\n2024-01-12
        08:54:33 +0000      49 promptflow-runtime INFO     Process 6280 finished\n2024-01-12
        08:54:33 +0000      49 promptflow-runtime INFO     [49] Child process finished!\n2024-01-12
        08:54:33 +0000      49 promptflow-runtime INFO     [run1] End processing bulk
        run\n2024-01-12 08:54:33 +0000      49 promptflow-runtime INFO     Cleanup
        working dir /mnt/host/service/app/39649/requests/run1 for bulk run\n"'
    headers:
      connection:
      - keep-alive
      content-length:
      - '26914'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '1.063'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2/logContent
  response:
    body:
      string: '"2024-01-12 08:55:18 +0000      49 promptflow-runtime INFO     [run2]
        Receiving v2 bulk run request fb3450a2-5971-497b-9704-9f15f2716d12: {\"flow_id\":
        \"run2\", \"flow_run_id\": \"run2\", \"flow_source\": {\"flow_source_type\":
        1, \"flow_source_info\": {\"snapshot_id\": \"a25bab13-d2d7-4c36-83bf-96979de95507\"},
        \"flow_dag_file\": \"flow.dag.yaml\"}, \"log_path\": \"https://promptfloweast4063704120.blob.core.windows.net/azureml/ExperimentRun/dcid.run2/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=**data_scrubbed**&skoid=55b92eba-d7c7-4afd-ab76-7bb1cd345283&sktid=00000000-0000-0000-0000-000000000000&skt=2024-01-12T07%3A44%3A44Z&ske=2024-01-13T15%3A54%3A44Z&sks=b&skv=2019-07-07&st=2024-01-12T08%3A45%3A18Z&se=2024-01-12T16%3A55%3A18Z&sp=rcw\",
        \"app_insights_instrumentation_key\": \"InstrumentationKey=**data_scrubbed**;IngestionEndpoint=https://eastus-6.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/\",
        \"data_inputs\": {\"run.outputs\": \"azureml:/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/data/azureml_run1_output_data_flow_outputs/versions/1\"},
        \"inputs_mapping\": {\"number\": \"${run.outputs.output}\"}, \"azure_storage_setting\":
        {\"azure_storage_mode\": 1, \"storage_account_name\": \"promptfloweast4063704120\",
        \"blob_container_name\": \"azureml-blobstore-3e123da1-f9a5-4c91-9234-8d9ffbb39ff5\",
        \"flow_artifacts_root_path\": \"promptflow/PromptFlowArtifacts/run2\", \"blob_container_sas_token\":
        \"?sv=2019-07-07&sr=c&sig=**data_scrubbed**&skoid=55b92eba-d7c7-4afd-ab76-7bb1cd345283&sktid=00000000-0000-0000-0000-000000000000&skt=2024-01-12T08%3A55%3A18Z&ske=2024-01-19T08%3A55%3A18Z&sks=b&skv=2019-07-07&se=2024-01-19T08%3A55%3A18Z&sp=racwl\",
        \"output_datastore_name\": \"workspaceblobstore\"}}\n2024-01-12 08:55:18 +0000      49
        promptflow-runtime INFO     Runtime version: 20231204.v4. PromptFlow version:
        1.2.0rc1\n2024-01-12 08:55:18 +0000      49 promptflow-runtime INFO     Updating
        run2 to Status.Preparing...\n2024-01-12 08:55:19 +0000      49 promptflow-runtime
        INFO     Downloading snapshot to /mnt/host/service/app/39649/requests/run2\n2024-01-12
        08:55:19 +0000      49 promptflow-runtime INFO     Get snapshot sas url for
        a25bab13-d2d7-4c36-83bf-96979de95507...\n2024-01-12 08:55:25 +0000      49
        promptflow-runtime INFO     Downloading snapshot a25bab13-d2d7-4c36-83bf-96979de95507
        from uri https://promptfloweast4063704120.blob.core.windows.net/snapshotzips/promptflow-eastus:3e123da1-f9a5-4c91-9234-8d9ffbb39ff5:snapshotzip/a25bab13-d2d7-4c36-83bf-96979de95507.zip...\n2024-01-12
        08:55:25 +0000      49 promptflow-runtime INFO     Downloaded file /mnt/host/service/app/39649/requests/run2/a25bab13-d2d7-4c36-83bf-96979de95507.zip
        with size 515 for snapshot a25bab13-d2d7-4c36-83bf-96979de95507.\n2024-01-12
        08:55:25 +0000      49 promptflow-runtime INFO     Download snapshot a25bab13-d2d7-4c36-83bf-96979de95507
        completed.\n2024-01-12 08:55:25 +0000      49 promptflow-runtime INFO     Successfully
        download snapshot to /mnt/host/service/app/39649/requests/run2\n2024-01-12
        08:55:25 +0000      49 promptflow-runtime INFO     About to execute a python
        flow.\n2024-01-12 08:55:25 +0000      49 promptflow-runtime INFO     Use spawn
        method to start child process.\n2024-01-12 08:55:25 +0000      49 promptflow-runtime
        INFO     Starting to check process 6515 status for run run2\n2024-01-12 08:55:25
        +0000      49 promptflow-runtime INFO     Start checking run status for run
        run2\n2024-01-12 08:55:29 +0000    6515 promptflow-runtime INFO     [49--6515]
        Start processing flowV2......\n2024-01-12 08:55:29 +0000    6515 promptflow-runtime
        INFO     Runtime version: 20231204.v4. PromptFlow version: 1.2.0rc1\n2024-01-12
        08:55:29 +0000    6515 promptflow-runtime INFO     Setting mlflow tracking
        uri...\n2024-01-12 08:55:29 +0000    6515 promptflow-runtime INFO     Validating
        ''AzureML Data Scientist'' user authentication...\n2024-01-12 08:55:29 +0000    6515
        promptflow-runtime INFO     Successfully validated ''AzureML Data Scientist''
        user authentication.\n2024-01-12 08:55:30 +0000    6515 promptflow-runtime
        INFO     Using AzureMLRunStorageV2\n2024-01-12 08:55:30 +0000    6515 promptflow-runtime
        INFO     Setting mlflow tracking uri to ''azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/promptflow-eastus''\n2024-01-12
        08:55:30 +0000    6515 promptflow-runtime INFO     Initialized blob service
        client for AzureMLRunTracker.\n2024-01-12 08:55:30 +0000    6515 promptflow-runtime
        INFO     Setting mlflow tracking uri to ''azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/promptflow-eastus''\n2024-01-12
        08:55:30 +0000    6515 promptflow-runtime INFO     Resolve data from url finished
        in 0.5992864752188325 seconds\n2024-01-12 08:55:30 +0000    6515 promptflow-runtime
        INFO     Starting the aml run ''run2''...\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Using fork, process count: 10\n2024-01-12 08:55:31
        +0000    6565 execution.bulk     INFO     Process 6565 started.\n2024-01-12
        08:55:31 +0000    6570 execution.bulk     INFO     Process 6570 started.\n2024-01-12
        08:55:31 +0000    6579 execution.bulk     INFO     Process 6579 started.\n2024-01-12
        08:55:31 +0000    6585 execution.bulk     INFO     Process 6585 started.\n2024-01-12
        08:55:31 +0000    6592 execution.bulk     INFO     Process 6592 started.\n2024-01-12
        08:55:31 +0000    6570 execution          ERROR    Node mod_three in line
        2 failed. Exception: Execution failure in ''mod_three'': (Exception) cannot
        mod 3!.\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_three'': (Exception) cannot mod 3!\n2024-01-12 08:55:31 +0000    6570
        execution          ERROR    Execution of one node has failed. Cancelling all
        running nodes: mod_three.\n2024-01-12 08:55:31 +0000    6515 execution.bulk     INFO     Process
        name: ForkProcess-64:2, Process id: 6565, Line number: 0 start execution.\n2024-01-12
        08:55:31 +0000    6605 execution.bulk     INFO     Process 6605 started.\n2024-01-12
        08:55:31 +0000    6515 execution.bulk     INFO     Process name: ForkProcess-64:4,
        Process id: 6570, Line number: 2 start execution.\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Process name: ForkProcess-64:3, Process id: 6579,
        Line number: 4 start execution.\n2024-01-12 08:55:31 +0000    6515 execution.bulk     INFO     Process
        name: ForkProcess-64:5, Process id: 6585, Line number: 6 start execution.\n2024-01-12
        08:55:31 +0000    6515 execution.bulk     INFO     Process name: ForkProcess-64:6,
        Process id: 6592, Line number: 8 start execution.\n2024-01-12 08:55:31 +0000    6622
        execution.bulk     INFO     Process 6622 started.\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Process name: ForkProcess-64:9, Process id: 6605,
        Line number: 10 start execution.\n2024-01-12 08:55:31 +0000    6515 execution.bulk     INFO     Process
        name: ForkProcess-64:10, Process id: 6622, Line number: 12 start execution.\n2024-01-12
        08:55:31 +0000    6515 execution.bulk     INFO     Process name: ForkProcess-64:2,
        Process id: 6565, Line number: 0 completed.\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Finished 1 / 10 lines.\n2024-01-12 08:55:31 +0000    6614
        execution.bulk     INFO     Process 6614 started.\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Average execution time for completed lines: 0.36
        seconds. Estimated time for incomplete lines: 3.24 seconds.\n2024-01-12 08:55:31
        +0000    6579 execution          ERROR    Node mod_three in line 4 failed.
        Exception: Execution failure in ''mod_three'': (Exception) cannot mod 3!.\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_three'': (Exception) cannot mod 3!\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Process name: ForkProcess-64:11, Process id: 6614,
        Line number: 14 start execution.\n2024-01-12 08:55:31 +0000    6592 execution          ERROR    Node
        mod_three in line 8 failed. Exception: Execution failure in ''mod_three'':
        (Exception) cannot mod 3!.\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_three'': (Exception) cannot mod 3!\n2024-01-12 08:55:31 +0000    6579
        execution          ERROR    Execution of one node has failed. Cancelling all
        running nodes: mod_three.\n2024-01-12 08:55:31 +0000    6515 execution.bulk     INFO     Process
        name: ForkProcess-64:2, Process id: 6565, Line number: 16 start execution.\n2024-01-12
        08:55:31 +0000    6592 execution          ERROR    Execution of one node has
        failed. Cancelling all running nodes: mod_three.\n2024-01-12 08:55:31 +0000    6565
        execution          ERROR    Node mod_three in line 16 failed. Exception: Execution
        failure in ''mod_three'': (Exception) cannot mod 3!.\nTraceback (most recent
        call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39649/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_three'': (Exception) cannot mod 3!\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Process name: ForkProcess-64:10, Process id: 6622,
        Line number: 12 completed.\n2024-01-12 08:55:31 +0000    6565 execution          ERROR    Execution
        of one node has failed. Cancelling all running nodes: mod_three.\n2024-01-12
        08:55:31 +0000    6515 execution.bulk     INFO     Process name: ForkProcess-64:4,
        Process id: 6570, Line number: 2 completed.\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Finished 3 / 10 lines.\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Finished 3 / 10 lines.\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Average execution time for completed lines: 0.15
        seconds. Estimated time for incomplete lines: 1.05 seconds.\n2024-01-12 08:55:31
        +0000    6515 execution.bulk     INFO     Process name: ForkProcess-64:6,
        Process id: 6592, Line number: 8 completed.\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Process name: ForkProcess-64:3, Process id: 6579,
        Line number: 4 completed.\n2024-01-12 08:55:31 +0000    6515 execution.bulk     INFO     Average
        execution time for completed lines: 0.16 seconds. Estimated time for incomplete
        lines: 1.12 seconds.\n2024-01-12 08:55:31 +0000    6515 execution.bulk     INFO     Process
        name: ForkProcess-64:5, Process id: 6585, Line number: 6 completed.\n2024-01-12
        08:55:31 +0000    6515 execution.bulk     INFO     Process name: ForkProcess-64:10,
        Process id: 6622, Line number: 18 start execution.\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Finished 6 / 10 lines.\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Finished 6 / 10 lines.\n2024-01-12 08:55:31 +0000    6515
        execution.bulk     INFO     Process name: ForkProcess-64:9, Process id: 6605,
        Line number: 10 completed.\n2024-01-12 08:55:31 +0000    6515 execution.bulk     INFO     Process
        name: ForkProcess-64:2, Process id: 6565, Line number: 16 completed.\n2024-01-12
        08:55:31 +0000    6515 execution.bulk     INFO     Finished 8 / 10 lines.\n2024-01-12
        08:55:31 +0000    6515 execution.bulk     INFO     Average execution time
        for completed lines: 0.09 seconds. Estimated time for incomplete lines: 0.36
        seconds.\n2024-01-12 08:55:31 +0000    6515 execution.bulk     INFO     Average
        execution time for completed lines: 0.1 seconds. Estimated time for incomplete
        lines: 0.4 seconds.\n2024-01-12 08:55:32 +0000    6515 execution.bulk     INFO     Finished
        8 / 10 lines.\n2024-01-12 08:55:32 +0000    6515 execution.bulk     INFO     Finished
        8 / 10 lines.\n2024-01-12 08:55:32 +0000    6515 execution.bulk     INFO     Average
        execution time for completed lines: 0.08 seconds. Estimated time for incomplete
        lines: 0.16 seconds.\n2024-01-12 08:55:32 +0000    6515 execution.bulk     INFO     Process
        name: ForkProcess-64:11, Process id: 6614, Line number: 14 completed.\n2024-01-12
        08:55:32 +0000    6515 execution.bulk     INFO     Process name: ForkProcess-64:10,
        Process id: 6622, Line number: 18 completed.\n2024-01-12 08:55:32 +0000    6515
        execution.bulk     INFO     Average execution time for completed lines: 0.08
        seconds. Estimated time for incomplete lines: 0.16 seconds.\n2024-01-12 08:55:32
        +0000    6515 execution.bulk     INFO     Average execution time for completed
        lines: 0.09 seconds. Estimated time for incomplete lines: 0.18 seconds.\n2024-01-12
        08:55:32 +0000    6515 execution.bulk     INFO     Finished 10 / 10 lines.\n2024-01-12
        08:55:32 +0000    6515 execution.bulk     INFO     Finished 10 / 10 lines.\n2024-01-12
        08:55:32 +0000    6515 execution.bulk     INFO     Average execution time
        for completed lines: 0.08 seconds. Estimated time for incomplete lines: 0.0
        seconds.\n2024-01-12 08:55:32 +0000    6515 execution.bulk     INFO     Average
        execution time for completed lines: 0.08 seconds. Estimated time for incomplete
        lines: 0.0 seconds.\n2024-01-12 08:56:02 +0000    6515 execution          ERROR    6/10
        flow run failed, indexes: [1,2,4,5,7,8], exception of index 1: Execution failure
        in ''mod_three'': (Exception) cannot mod 3!\n2024-01-12 08:56:04 +0000    6515
        execution.bulk     INFO     Upload status summary metrics for run run2 finished
        in 1.3678363300859928 seconds\n2024-01-12 08:56:04 +0000    6515 promptflow-runtime
        INFO     Successfully write run properties {\"azureml.promptflow.total_tokens\":
        0, \"_azureml.evaluate_artifacts\": \"[{\\\"path\\\": \\\"instance_results.jsonl\\\",
        \\\"type\\\": \\\"table\\\"}]\"} with run id ''run2''\n2024-01-12 08:56:04
        +0000    6515 execution.bulk     INFO     Upload RH properties for run run2
        finished in 0.07642840500921011 seconds\n2024-01-12 08:56:04 +0000    6515
        promptflow-runtime INFO     Creating unregistered output Asset for Run run2...\n2024-01-12
        08:56:04 +0000    6515 promptflow-runtime INFO     Created debug_info Asset:
        azureml://locations/eastus/workspaces/00000/data/azureml_run2_output_data_debug_info/versions/1\n2024-01-12
        08:56:04 +0000    6515 promptflow-runtime INFO     Creating unregistered output
        Asset for Run run2...\n2024-01-12 08:56:05 +0000    6515 promptflow-runtime
        INFO     Created flow_outputs output Asset: azureml://locations/eastus/workspaces/00000/data/azureml_run2_output_data_flow_outputs/versions/1\n2024-01-12
        08:56:05 +0000    6515 promptflow-runtime INFO     Creating Artifact for Run
        run2...\n2024-01-12 08:56:05 +0000    6515 promptflow-runtime INFO     Created
        instance_results.jsonl Artifact.\n2024-01-12 08:56:05 +0000    6515 promptflow-runtime
        INFO     Patching run2...\n2024-01-12 08:56:05 +0000    6515 promptflow-runtime
        WARNING  [run2] Run failed. Execution stackTrace: Traceback (most recent call
        last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  [REDACTED:
        External StackTrace]\n\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  [REDACTED:
        External StackTrace]\n\n2024-01-12 08:56:05 +0000    6515 promptflow-runtime
        INFO     Ending the aml run ''run2'' with status ''Completed''...\n2024-01-12
        08:56:06 +0000      49 promptflow-runtime INFO     Process 6515 finished\n2024-01-12
        08:56:06 +0000      49 promptflow-runtime INFO     [49] Child process finished!\n2024-01-12
        08:56:06 +0000      49 promptflow-runtime INFO     [run2] End processing bulk
        run\n2024-01-12 08:56:06 +0000      49 promptflow-runtime INFO     Cleanup
        working dir /mnt/host/service/app/39649/requests/run2 for bulk run\n"'
    headers:
      connection:
      - keep-alive
      content-length:
      - '22442'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.427'
    status:
      code: 200
      message: OK
version: 1
