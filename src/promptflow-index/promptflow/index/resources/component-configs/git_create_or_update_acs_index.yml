$schema: https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
type: pipeline

version: 0.0.5
name: llm_ingest_git_to_acs_basic
display_name: LLM - Git to ACS Pipeline
is_deterministic: false

description: Single job pipeline to import data from Github, chunk, and create embeddings index

settings:
   default_compute: serverless

inputs:
   acs_config:
     type: string
     description: "JSON describing the acs index to create or update."
   acs_connection:
     type: string
     optional: true
     description: "Azure Cognitive Search workspace connection ARM ID"
   # register settings
   embeddings_dataset_name:
     type: string
     optional: true
     default: "VectorIndexDS"
     description: "Name of the vector index"
   # compute settings
   serverless_instance_count:
     type: integer
     default: 1
     optional: true
     description: "Instance count to use for the serverless compute"
   serverless_instance_type:
     type: string
     default: "Standard_E8s_v3"
     optional: true
     description: "The Instance Type to be used for the serverless compute"
   # git clone component
   git_connection:
     type: string
     optional: true
     description: "Github workspace connection ARM ID"
   git_repository:
     type: string
     description: "Repository with documents that need to imported and used to create the model."
   branch_name:
     type: string
     optional: true
     description: "The branch name to pull from the git repository, default picked by git if not specified."
   authentication_key_prefix:
     type: string
     optional: true
     description: "<PREFIX>-USER and <PREFIX>-PASS are the expected names of two Secrets in the Workspace Key Vault which will be used for authenticated when pulling the given git repo."
   # Data Chunker
   chunk_size:
     type: integer
     default: 1024
     description: "Chunk size (by token) to pass into the text splitter before performing embeddings"
   chunk_overlap:
     type: integer
     default: 0
     description: "Overlap of content (by token) between the chunks"
   input_glob:
     type: string
     optional: true
     description: "Glob pattern to filter files from the input folder. e.g. 'articles/**/*''"
   max_sample_files:
     type: integer
     default: -1
     optional: true
     description: "Number of files read in during QA test data generation"
   chunk_prepend_summary:
     type: string
     enum:
      - "True"
      - "False"
     default: "False"
     optional: true
     description:  "Whether to include summary of document on top of every chunk for that document."
   data_source_url:
     type: string
     description: "The url which can be appended to file names to form citation links for documents"
   document_path_replacement_regex:
     type: string
     optional: true
     description: "A JSON string with two fields, 'match_pattern' and 'replacement_pattern' to be used with re.sub on the source url. e.g. '{\"match_pattern\": \"(.*)/articles/(.*)\", \"replacement_pattern\": \"\\1/\\2\"}' would remove '/articles' from the middle of the url."
   # Embeddings components
   embeddings_container:
    type: uri_folder
    optional: true
    mode: direct
    description: "Folder to contain generated embeddings. Should be parent folder of the 'embeddings' output path used for for this component. Will compare input data to existing embeddings and only embed changed/new data, reusing existing chunks."
   embeddings_model:
    type: string
    default: "azure_open_ai://deployment/text-embedding-ada-002/model/text-embedding-ada-002"
    description: "The model to use to embed data. E.g. 'hugging_face://model/sentence-transformers/all-mpnet-base-v2' or 'azure_open_ai://deployment/{deployment_name}/model/{model_name}'"
   embedding_connection:
    type: string
    optional: true
    description: "Azure OpenAI workspace connection ARM ID for embeddings"

outputs:
   acs_index:
     type: uri_folder
     description: "Folder containing the ACS MLIndex. Deserialized using azureml.rag.mlindex._mlindex(uri)."

#defaults:
#  compute: azureml:cpu-cluster
jobs:
  #############
  git_clone_job:
    type: command
    resources:
      instance_count: ${{parent.inputs.serverless_instance_count}}
      instance_type: ${{parent.inputs.serverless_instance_type}}
      properties:
        compute_specification:
          automatic: true
    component: 'azureml://registries/azureml-preview/components/llm_rag_git_clone/versions/0.0.8'
    inputs:
      git_repository: ${{parent.inputs.git_repository}}
      branch_name: ${{parent.inputs.branch_name}}
      authentication_key_prefix: ${{parent.inputs.authentication_key_prefix}}
    outputs:
      output_data:
        type: uri_folder
    # TODO: Fix env var name after git connection UI Support
    environment_variables:
      AZUREML_WORKSPACE_CONNECTION_ID_GIT_UNUSED : ${{parent.inputs.git_connection}}
  ############
  data_chunking_job:
    type: command
    resources:
      instance_count: ${{parent.inputs.serverless_instance_count}}
      instance_type: ${{parent.inputs.serverless_instance_type}}
      properties:
        compute_specification:
          automatic: true
    component: 'azureml://registries/azureml-preview/components/llm_rag_crack_and_chunk/versions/0.0.8'
    inputs:
      input_data: ${{parent.jobs.git_clone_job.outputs.output_data}}
      input_glob: ${{parent.inputs.input_glob}}
      chunk_size: ${{parent.inputs.chunk_size}}
      chunk_overlap: ${{parent.inputs.chunk_overlap}}
      data_source_url: ${{parent.inputs.data_source_url}}
      document_path_replacement_regex: ${{parent.inputs.document_path_replacement_regex}}
      include_summary: ${{parent.inputs.chunk_prepend_summary}}
      max_sample_files: ${{parent.inputs.max_sample_files}}
    outputs:
      output_chunks:
        type: uri_folder
    environment_variables:
       AZUREML_WORKSPACE_CONNECTION_ID_AOAI : ${{parent.inputs.llm_connection}}
  ############
  embeddings_parallel_job:
    type: command
    resources:
      instance_count: ${{parent.inputs.serverless_instance_count}}
      instance_type: ${{parent.inputs.serverless_instance_type}}
      properties:
        compute_specification:
          automatic: true
    retry_settings:
      timeout: 600
      max_retries: 3
    mini_batch_size: "3"
    mini_batch_error_threshold: 0
    logging_level: "INFO"
    component: 'azureml://registries/azureml-preview/components/llm_rag_generate_embeddings_parallel/versions/0.0.8'
    inputs:
      chunks_source:
        type: uri_folder
        path: ${{parent.jobs.data_chunking_job.outputs.output_chunks}}
      embeddings_container: ${{parent.inputs.embeddings_container}}
      embeddings_model: ${{parent.inputs.embeddings_model}}
    outputs:
      embeddings:
        type: uri_folder
    environment_variables:
       AZUREML_WORKSPACE_CONNECTION_ID_AOAI : ${{parent.inputs.embedding_connection}}
  ############
  create_acs_index_job:
    type: command
    resources:
      instance_count: ${{parent.inputs.serverless_instance_count}}
      instance_type: ${{parent.inputs.serverless_instance_type}}
      properties:
        compute_specification:
          automatic: true
    component: 'azureml://registries/azureml-preview/components/llm_rag_update_acs_index/versions/0.0.8'
    inputs:
      embeddings:
        type: uri_folder
        path: ${{parent.jobs.embeddings_parallel_job.outputs.embeddings}}
      acs_config: ${{parent.inputs.acs_config}}
    outputs:
      index: ${{parent.outputs.acs_index}}
    environment_variables:
       AZUREML_WORKSPACE_CONNECTION_ID_AOAI : ${{parent.inputs.embedding_connection}}
       AZUREML_WORKSPACE_CONNECTION_ID_ACS : ${{parent.inputs.acs_connection}}
  ############
  register_mlindex_asset_job:
    type: command
    resources:
      instance_count: ${{parent.inputs.serverless_instance_count}}
      instance_type: ${{parent.inputs.serverless_instance_type}}
      properties:
        compute_specification:
          automatic: true
    component: 'azureml://registries/azureml-preview/components/llm_rag_register_mlindex_asset/versions/0.0.8'
    inputs:
      storage_uri: ${{parent.jobs.create_acs_index_job.outputs.index}}
      asset_name: ${{parent.inputs.embeddings_dataset_name}}
    outputs:
      asset_id:
        type: uri_file